pub mod dump;
pub mod hash;
pub mod http;
pub mod id;
pub mod unix;

use crate::{config, config::structs::Server, file, helpers};

use std::{
    collections::{BTreeMap, HashSet},
    env,
    fs::File,
    path::PathBuf,
    sync::{Arc, Mutex},
    thread,
    time::Duration,
};

#[cfg(not(target_os = "linux"))]
use std::collections::HashMap;

use home;

use dashmap::DashMap;
use once_cell::sync::Lazy;

use nix::{
    sys::signal::{kill, Signal},
    unistd::Pid,
};

use chrono::{DateTime, Utc};
use global_placeholders::global;
use macros_rs::{crashln, string, ternary, then};
use serde::{Deserialize, Serialize};
use utoipa::ToSchema;

// Global process handle storage to prevent child processes from being dropped and becoming zombies
// Key: PID, Value: Child process handle wrapped in Arc<Mutex> for thread-safe access
// This is the PM2-like daemon state that keeps processes alive
pub static PROCESS_HANDLES: Lazy<DashMap<i64, Arc<Mutex<std::process::Child>>>> =
    Lazy::new(DashMap::new);

// Constants for process termination waiting
const MAX_TERMINATION_WAIT_ATTEMPTS: u32 = 50;
const TERMINATION_CHECK_INTERVAL_MS: u64 = 100;

// Grace period for process status determination
// Processes within this period after start show as "starting" instead of "crashed"
// This prevents false crash reports during slow process initialization and restart cycles
const STATUS_GRACE_PERIOD_SECS: i64 = 15;

// Anti-spam restart cooldown constants
// Simplified fixed delay for restart attempts as per requirement #4
pub const RESTART_COOLDOWN_SECS: u64 = 2;
// No exponential backoff - use same 2s delay for all restarts
pub const FAILED_RESTART_COOLDOWN_SECS: u64 = 2;
// Interval for periodic cooldown logging to reduce log noise
pub const COOLDOWN_LOG_INTERVAL_SECS: i64 = 2;
// Wait time after killing processes to allow OS resource cleanup
pub const PROCESS_CLEANUP_WAIT_MS: u64 = 500;

/// Write timestamp file durably to disk with fsync
/// This ensures the timestamp is persisted before the function returns,
/// preventing race conditions where the daemon might check for the file
/// before it's fully written to disk.
pub fn write_action_timestamp(id: usize) -> Result<(), std::io::Error> {
    use std::io::Write;
    use std::os::unix::fs::OpenOptionsExt;

    if let Some(home_dir) = home::home_dir() {
        let action_file = format!("{}/.opm/last_action_{}.timestamp", home_dir.display(), id);
        let timestamp = Utc::now().to_rfc3339();

        // Open file with O_SYNC flag to ensure data is written synchronously
        let mut file = std::fs::OpenOptions::new()
            .write(true)
            .create(true)
            .truncate(true)
            .mode(0o644)
            .open(&action_file)?;

        // Write the timestamp
        file.write_all(timestamp.as_bytes())?;

        // Explicitly sync to ensure data is flushed to disk
        file.sync_all()?;

        log::debug!("Created and synced timestamp file for process {}", id);
    }
    Ok(())
}

/// Wait for a process to terminate gracefully
/// Uses libc::kill(pid, 0) to check if process exists, which is the same approach
/// as pid::running() but implemented here to avoid circular dependencies.
/// This is more reliable than trying to create a process handle that could fail
/// for other reasons (permissions, etc.)
/// Returns true if process terminated, false if timeout reached
fn wait_for_process_termination(pid: i64) -> bool {
    // Don't wait for invalid PIDs - they're already "terminated"
    // PID 0 signals all processes in current process group (not a specific process)
    // Negative PIDs signal process groups (not individual processes)
    // PID <= 0 is used internally to indicate "no valid PID" when a process crashes
    // These are not valid individual process IDs to wait for termination
    if pid <= 0 {
        return true;
    }

    for _ in 0..MAX_TERMINATION_WAIT_ATTEMPTS {
        // Check if process is still running using libc::kill with signal 0
        // This returns 0 if the process exists, -1 if it doesn't (or permission denied)
        let process_exists = unsafe { libc::kill(pid as i32, 0) == 0 };
        if !process_exists {
            return true; // Process has terminated (or we don't have permission to check)
        }
        thread::sleep(Duration::from_millis(TERMINATION_CHECK_INTERVAL_MS));
    }
    false // Timeout reached, process is still running
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct ItemSingle {
    pub info: Info,
    pub stats: Stats,
    pub watch: Watch,
    pub log: Log,
    pub raw: Raw,
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct Info {
    pub id: usize,
    pub pid: i64,
    pub name: String,
    pub status: String,
    #[schema(value_type = String, example = "/path")]
    pub path: PathBuf,
    pub uptime: String,
    pub command: String,
    pub children: Vec<i64>,
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct Stats {
    pub restarts: u64,
    pub start_time: i64,
    pub cpu_percent: Option<f64>,
    pub memory_usage: Option<MemoryInfo>,
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct MemoryInfo {
    pub rss: u64,
    pub vms: u64,
}

impl From<unix::NativeMemoryInfo> for MemoryInfo {
    fn from(native: unix::NativeMemoryInfo) -> Self {
        MemoryInfo {
            rss: native.rss(),
            vms: native.vms(),
        }
    }
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct Log {
    pub out: String,
    pub error: String,
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct Raw {
    pub running: bool,
    pub crashed: bool,
    pub crashes: u64,
}

#[derive(Clone)]
pub struct LogInfo {
    pub out: String,
    pub error: String,
}

#[derive(Serialize, Deserialize, ToSchema)]
pub struct ProcessItem {
    pub pid: i64,
    pub id: usize,
    pub cpu: String,
    pub mem: String,
    pub name: String,
    pub restarts: u64,
    pub status: String,
    pub uptime: String,
    #[schema(example = "/path")]
    pub watch_path: String,
    #[schema(value_type = String, example = "2000-01-01T01:00:00.000Z")]
    pub start_time: DateTime<Utc>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub agent_id: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub agent_name: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub agent_api_endpoint: Option<String>,
}

#[derive(Clone)]
pub struct ProcessWrapper {
    pub id: usize,
    pub runner: Arc<Mutex<Runner>>,
}

pub type Env = BTreeMap<String, String>;

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct Process {
    pub id: usize,
    /// Process ID - persisted to enable state synchronization via socket
    pub pid: i64,
    /// PID of the parent shell process when running commands through a shell.
    /// This is set when the command is executed via a shell (e.g., bash -c 'script.sh')
    /// and shell_pid != actual_pid. Used for accurate CPU monitoring of shell scripts.
    pub shell_pid: Option<i64>,
    pub env: Env,
    pub name: String,
    pub path: PathBuf,
    pub script: String,
    /// Restart counter - tracks how many times process has been restarted by daemon
    /// Serialized for socket communication to display correctly in CLI commands
    /// Also persisted to dump file, maintaining restart count across daemon restarts
    pub restarts: u64,
    pub running: bool,
    pub crash: Crash,
    pub watch: Watch,
    /// Child process IDs - persisted to enable state synchronization via socket
    pub children: Vec<i64>,
    /// Process start timestamp - persisted to enable accurate uptime tracking
    pub started: DateTime<Utc>,
    /// Maximum memory limit in bytes (0 = no limit)
    #[serde(default)]
    pub max_memory: u64,
    /// Agent ID that owns this process (None for local processes)
    #[serde(default)]
    pub agent_id: Option<String>,
    /// Timestamp until which the process is frozen (auto-restart paused)
    /// None means not frozen, Some means frozen until the specified time
    #[serde(default)]
    pub frozen_until: Option<DateTime<Utc>>,
    /// Timestamp of last action (start/restart/reload/restore) for per-process crash detection delay
    /// Persisted to enable proper timing checks across daemon restarts
    pub last_action_at: DateTime<Utc>,
    /// Flag to indicate manual stop (user-initiated via 'opm stop')
    /// When true, prevents daemon from treating process exit as a crash
    /// Persisted temporarily to communicate with daemon, reset after handling
    pub manual_stop: bool,
    /// Flag to indicate process reached error state (restart limit exceeded)
    /// When true, process has crashed repeatedly and will not be restarted
    /// Reset when user manually starts/restarts the process
    #[serde(default)]
    pub errored: bool,
    /// Timestamp of last restart attempt for anti-spam cooldown
    /// Used to prevent rapid restart loops by enforcing minimum delay between attempts
    #[serde(default)]
    pub last_restart_attempt: Option<DateTime<Utc>>,
    /// Count of consecutive failed restart attempts (port conflicts, etc.)
    /// Reset to 0 on successful restart. Used to implement exponential backoff
    #[serde(default)]
    pub failed_restart_attempts: u32,
    /// Session ID of the spawned process (for session-based tracking)
    /// Used to detect if any process in the session is still alive
    #[serde(default)]
    pub session_id: Option<i64>,
    /// Process start time (system uptime seconds) for PID reuse detection
    /// Persisted to detect when PID has been recycled by OS
    #[serde(default)]
    pub process_start_time: Option<u64>,
    /// Indicates this process is a wrapper/tree (bash script with children)
    /// Used to display tree indicator in UI
    #[serde(default)]
    pub is_process_tree: bool,
}

impl Process {
    /// Check if the process is in restart cooldown period
    /// Returns true if the process is waiting for cooldown to expire before next restart attempt
    pub fn is_in_restart_cooldown(&self) -> bool {
        self.last_restart_attempt
            .map(|t| {
                let secs_since = (Utc::now() - t).num_seconds();
                let cooldown_delay = if self.failed_restart_attempts > 0 {
                    FAILED_RESTART_COOLDOWN_SECS
                } else {
                    RESTART_COOLDOWN_SECS
                };
                secs_since < cooldown_delay as i64
            })
            .unwrap_or(false)
    }
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct Crash {
    pub crashed: bool,
}

#[derive(Clone, Debug, Deserialize, Serialize, ToSchema)]
pub struct Watch {
    pub enabled: bool,
    #[schema(example = "/path")]
    pub path: String,
    pub hash: String,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct Runner {
    pub id: id::Id,
    #[serde(skip, default)]
    pub remote: Option<Remote>,
    pub list: BTreeMap<usize, Process>,
}

#[derive(Clone, Debug)]
pub struct Remote {
    address: String,
    token: Option<String>,
    pub config: RemoteConfig,
}

#[derive(Clone, Debug, Deserialize)]
pub struct RemoteConfig {
    pub shell: String,
    pub args: Vec<String>,
    pub log_path: String,
}

pub enum Status {
    Offline,
    Running,
}

impl Status {
    pub fn to_bool(&self) -> bool {
        match self {
            Status::Offline => false,
            Status::Running => true,
        }
    }
}

/// Process metadata
pub struct ProcessMetadata {
    /// Process name
    pub name: String,
    /// Shell command
    pub shell: String,
    /// Command
    pub command: String,
    /// Log path
    pub log_path: String,
    /// Arguments
    pub args: Vec<String>,
    /// Environment variables
    pub env: Vec<String>,
}

macro_rules! lock {
    ($runner:expr) => {{
        match $runner.lock() {
            Ok(runner) => runner,
            Err(err) => crashln!("Unable to lock mutex: {err}"),
        }
    }};
}

fn kill_children(children: Vec<i64>) {
    for pid in children {
        match kill(Pid::from_raw(pid as i32), Signal::SIGTERM) {
            Ok(_) => {}
            Err(nix::errno::Errno::ESRCH) => {
                // Process already terminated
            }
            Err(err) => {
                log::error!("Failed to stop pid {}: {err:?}", pid);
            }
        }
    }
}

/// Load environment variables from .env file in the specified directory
fn load_dotenv(path: &PathBuf) -> BTreeMap<String, String> {
    let env_file = path.join(".env");
    let mut env_vars = BTreeMap::new();

    if env_file.exists() && env_file.is_file() {
        match dotenvy::from_path_iter(&env_file) {
            Ok(iter) => {
                for item in iter {
                    match item {
                        Ok((key, value)) => {
                            env_vars.insert(key, value);
                        }
                        Err(err) => {
                            log::warn!("Failed to parse .env entry: {}", err);
                        }
                    }
                }
                if !env_vars.is_empty() {
                    log::info!(
                        "Loaded {} environment variables from .env file",
                        env_vars.len()
                    );
                }
            }
            Err(err) => {
                log::warn!("Failed to read .env file at {:?}: {}", env_file, err);
            }
        }
    }

    env_vars
}

/// Check if a process with the given PID is alive
/// Uses libc::kill with signal 0 to check process existence without sending a signal
/// Also checks if the process is a zombie (defunct), which should be treated as dead
///
/// Why zombie detection matters:
/// When a process crashes immediately after starting, it can become a zombie (defunct) process
/// that still exists in the process table. The parent shell hasn't yet read its exit status via wait().
/// Without zombie detection, libc::kill(pid, 0) returns success for zombies, causing the daemon to
/// incorrectly report them as "online" and stop attempting restarts. By detecting zombies and treating
/// them as dead, we ensure the daemon continues restart attempts until the max threshold is reached.
///
/// PID <= 0 is never considered alive:
/// - PID 0 signals all processes in the current process group
/// - Negative PIDs signal process groups
/// - These are not valid individual process IDs
pub fn is_pid_alive(pid: i64) -> bool {
    if pid <= 0 {
        return false;
    }

    // First check if the PID exists using libc::kill
    // IMPORTANT: kill(pid, 0) returns 0 on success, -1 on error
    // We need to check errno to distinguish between:
    // - ESRCH (3): No such process - the process doesn't exist
    // - EPERM (1): Permission denied - the process exists but we can't signal it
    // If errno is EPERM, the process exists, so we should return true
    let result = unsafe { libc::kill(pid as i32, 0) };

    if result != 0 {
        // kill failed, check why
        let err = std::io::Error::last_os_error();
        let errno = err.raw_os_error().unwrap_or(0);

        // EPERM (1) means process exists but we don't have permission
        // This should be treated as "process is alive"
        if errno == libc::EPERM {
            // Process exists but permission denied - treat as alive
            return true;
        }

        // Any other error (especially ESRCH) means process doesn't exist
        return false;
    }

    // PID exists, but it might be a zombie (defunct)
    // Zombies are dead processes that still exist in the process table
    // They should be treated as dead for process monitoring purposes
    #[cfg(any(target_os = "linux", target_os = "macos"))]
    {
        if unix::is_process_zombie(pid as i32) {
            return false;
        }
    }

    true
}

/// Check if a PID would conflict with any existing tracked processes
/// Returns (has_duplicate, error_message) tuple
/// - has_duplicate: true if PID conflicts with an existing process
/// - error_message: human-readable description of the conflict
fn check_duplicate_pid(
    runner_list: &BTreeMap<usize, Process>,
    current_id: usize,
    new_pid: i64,
    new_shell_pid: Option<i64>,
) -> (bool, String) {
    for (existing_id, existing_process) in runner_list {
        // Skip the current process (for restart case)
        if *existing_id == current_id {
            continue;
        }
        
        // Check if the new process PID matches an existing process's main PID or shell_pid
        if existing_process.pid == new_pid && existing_process.pid > 0 {
            return (
                true,
                format!(
                    "PID {} is already tracked by process '{}' (id={})",
                    new_pid, existing_process.name, existing_id
                ),
            );
        }
        
        if let Some(existing_shell_pid) = existing_process.shell_pid {
            if existing_shell_pid == new_pid {
                return (
                    true,
                    format!(
                        "PID {} is already tracked as shell wrapper by process '{}' (id={})",
                        new_pid, existing_process.name, existing_id
                    ),
                );
            }
        }
        
        // Also check if the new shell_pid matches existing PIDs
        if let Some(new_shell_pid_val) = new_shell_pid {
            if existing_process.pid == new_shell_pid_val {
                return (
                    true,
                    format!(
                        "shell wrapper PID {} is already tracked as main PID by process '{}' (id={})",
                        new_shell_pid_val, existing_process.name, existing_id
                    ),
                );
            }
            
            if let Some(existing_shell_pid) = existing_process.shell_pid {
                if existing_shell_pid == new_shell_pid_val {
                    return (
                        true,
                        format!(
                            "shell wrapper PID {} is already tracked by process '{}' (id={})",
                            new_shell_pid_val, existing_process.name, existing_id
                        ),
                    );
                }
            }
        }
    }
    
    (false, String::new())
}

impl Runner {
    pub fn new() -> Self {
        // Read merged state (permanent + temporary)
        dump::read_merged()
    }

    /// Read merged state directly from memory cache without using socket
    /// This is for use by the daemon's own code to avoid recursion
    pub fn new_direct() -> Self {
        dump::read_merged_direct()
    }

    /// Read state from daemon only (no disk fallback)
    /// Should only be used when daemon is guaranteed to be running (e.g., during restore)
    pub fn new_from_daemon() -> Result<Self, String> {
        dump::read_from_daemon_only()
    }

    /// Refresh the runner state
    /// Note: This uses Runner::new() which queries via socket.
    /// Do not call from daemon context - use new_direct() instead.
    pub fn refresh(&self) -> Self {
        Runner::new()
    }

    pub fn connect(name: String, Server { address, token }: Server, verbose: bool) -> Option<Self> {
        let remote_config = match config::from(&address, token.as_deref()) {
            Ok(config) => config,
            Err(err) => {
                log::error!("{err}");
                return None;
            }
        };

        if let Ok(dump) = dump::from(&address, token.as_deref()) {
            then!(
                verbose,
                println!(
                    "{} Fetched remote (name={name}, address={address})",
                    *helpers::SUCCESS
                )
            );
            Some(Runner {
                remote: Some(Remote {
                    token,
                    address: string!(address),
                    config: remote_config,
                }),
                ..dump
            })
        } else {
            None
        }
    }

    pub fn start(
        &mut self,
        name: &String,
        command: &String,
        path: PathBuf,
        watch: &Option<String>,
        max_memory: u64,
    ) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::create(remote, name, command, path, watch) {
                crashln!(
                    "{} Failed to start create {name}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            let id = self.id.next();
            let config = config::read().runner;
            let crash = Crash { crashed: false };

            let watch = match watch {
                Some(watch) => Watch {
                    enabled: true,
                    path: string!(watch),
                    hash: hash::create(file::cwd().join(watch)),
                },
                None => Watch {
                    enabled: false,
                    path: string!(""),
                    hash: string!(""),
                },
            };

            // Load environment variables from .env file
            let dotenv_vars = load_dotenv(&path);
            let system_env = unix::env();

            // Prepare process environment with dotenv variables having priority
            let mut process_env = Vec::with_capacity(dotenv_vars.len() + system_env.len());
            // Add dotenv variables first (higher priority)
            for (key, value) in &dotenv_vars {
                process_env.push(format!("{}={}", key, value));
            }
            // Then add system environment
            process_env.extend(system_env);

            let result = match process_run(ProcessMetadata {
                args: config.args,
                name: name.clone(),
                shell: config.shell,
                command: command.clone(),
                log_path: config.log_path,
                env: process_env,
            }) {
                Ok(result) => result,
                Err(err) => {
                    log::error!("Failed to start process '{}': {}", name, err);
                    println!(
                        "{} Failed to start process '{}': {}",
                        *helpers::FAIL,
                        name,
                        err
                    );
                    return self;
                }
            };

            // Merge .env variables into the stored environment (dotenv takes priority)
            let mut stored_env: Env = env::vars().collect();
            // Extend with dotenv variables (this overwrites any existing keys)
            stored_env.extend(dotenv_vars);

            // Check for duplicate PIDs before inserting new process
            // This prevents tracking the same process multiple times
            // (unless it's a PM2-like multi-worker setup with legitimate parent-child relationships)
            let (has_duplicate, error_msg) = check_duplicate_pid(
                &self.list,
                id,
                result.pid,
                result.shell_pid,
            );
            
            if has_duplicate {
                log::warn!(
                    "[process] Duplicate PID detected: new process '{}' (id={}). {}",
                    name,
                    id,
                    error_msg
                );
                println!(
                    "{} Process '{}' not started: {}",
                    *helpers::FAIL,
                    name,
                    error_msg
                );
                return self;
            }

            self.list.insert(
                id,
                Process {
                    id,
                    pid: result.pid,
                    shell_pid: result.shell_pid,
                    path,
                    watch,
                    crash,
                    restarts: 0,
                    running: true,
                    children: vec![],
                    name: name.clone(),
                    started: Utc::now(),
                    script: command.clone(),
                    env: stored_env,
                    max_memory,
                    agent_id: None,     // Local processes don't have an agent
                    frozen_until: None, // Not frozen by default
                    last_action_at: Utc::now(),
                    manual_stop: false,         // Not manually stopped by default
                    errored: false,             // Not in error state by default
                    last_restart_attempt: None, // No restart attempt yet
                    failed_restart_attempts: 0, // No failures yet
                    session_id: result.session_id, // Store session ID for tracking
                    process_start_time: result.start_time, // Store for PID reuse detection
                    is_process_tree: result.shell_pid.is_some(), // Mark as tree if has shell wrapper
                },
            );

            // Create timestamp file for this new process to prevent daemon from
            // immediately marking it as crashed if it exits quickly during startup
            // Write with fsync to ensure timestamp is durably written before daemon checks
            if let Err(e) = write_action_timestamp(id) {
                log::warn!(
                    "Failed to create action timestamp file for process {}: {}",
                    id,
                    e
                );
            }
        }

        return self;
    }

    pub fn restart(&mut self, id: usize, dead: bool, increment_counter: bool) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::restart(remote, id) {
                crashln!(
                    "{} Failed to start process {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            // Create timestamp file FIRST (before spawning process or modifying state)
            // to prevent daemon from interfering during the entire restart operation.
            // This must be done before any state changes to ensure daemon sees it.
            // Skip for daemon-initiated restarts (dead=true) since daemon will handle those.
            if !dead {
                if let Err(e) = write_action_timestamp(id) {
                    log::warn!(
                        "Failed to create action timestamp file for process {}: {}",
                        id,
                        e
                    );
                }
            }

            let full_config = config::read();
            let config = full_config.runner;
            let max_restarts = full_config.daemon.restarts;

            // Clone the process data we need before making any modifications
            // This avoids borrowing issues with self.list
            let Process {
                path,
                script,
                name,
                running: was_running,
                ..
            } = self
                .list
                .get(&id)
                .unwrap_or_else(|| panic!("Process with id {} must exist", id))
                .clone();

            // Save the current working directory so we can restore it after restart
            // This is critical for the daemon - changing the working directory affects the daemon process
            // and can cause it to crash when trying to access its own files
            let original_dir = std::env::current_dir().ok();

            // Get mutable reference to process for modifications
            let process = self.process(id);

            // Reset counters when user manually starts a stopped process (not a restart)
            // This gives the process a fresh start after being stopped/crashed
            // - dead=false: user-initiated (not daemon)
            // - !increment_counter: start command (not restart)
            // - !was_running: process was stopped/crashed
            if !dead && !increment_counter && !was_running {
                process.restarts = 0;
                process.errored = false;
                log::info!(
                    "Resetting restart counter and errored flag for stopped process {} (id={})",
                    name,
                    id
                );
            }

            // Increment restart counter for manual restart/reload:
            // - dead=false (user-initiated, not daemon)
            // - increment_counter=true (restart/reload command)
            if !dead && increment_counter {
                process.restarts += 1;
                // Clear errored state when user manually restarts
                process.errored = false;
            }

            kill_children(process.children.clone());
            if let Err(err) = process_stop(process.pid) {
                log::warn!(
                    "Failed to stop process {} during restart: {}",
                    process.pid,
                    err
                );
                // Continue with restart even if stop fails - process may already be dead
            }

            // Wait for the process to actually terminate before starting a new one
            // This prevents conflicts when restarting processes that hold resources (e.g., network connections)
            if !wait_for_process_termination(process.pid) {
                log::warn!(
                    "Process {} did not terminate within timeout during restart",
                    process.pid
                );
            }

            if let Err(err) = std::env::set_current_dir(&path) {
                // Restore working directory before returning
                if let Some(ref dir) = original_dir {
                    let _ = std::env::set_current_dir(dir);
                }

                // When dead=true (crash restart), keep running=true so daemon will retry on next cycle
                // When dead=false (manual restart), set running=false to stop retrying until user manually restarts
                if !dead {
                    process.running = false;
                }
                process.children = vec![];
                // Reset PID to 0 to indicate process never successfully started
                // This prevents handle_restart_failure from marking it as crashed
                process.pid = 0;
                process.shell_pid = None;

                // Increment crash counter for restart failures to count against restart limit
                // When dead=true (daemon restart): don't increment (daemon already incremented)
                // When dead=false (manual restart): increment (first time counting this failure)
                self.handle_restart_failure(id, &name, max_restarts, !dead);
                // Note: handle_restart_failure sets crashed=true, so we don't need to set it here

                // Save state to persist counter increments and state changes
                self.save_after_restart_failure(dead);

                log::error!(
                    "Failed to set working directory {:?} for process {} during restart: {}",
                    path,
                    name,
                    err
                );
                println!(
                    "{} Failed to set working directory {:?}\nError: {:#?}",
                    *helpers::FAIL,
                    path,
                    err
                );
                return self;
            }

            // Load environment variables from .env file
            let dotenv_vars = load_dotenv(&path);
            let system_env = unix::env();

            // Prepare process environment with dotenv variables having priority
            let stored_env_vec: Vec<String> = process
                .env
                .iter()
                .map(|(key, value)| format!("{}={}", key, value))
                .collect();
            let mut temp_env =
                Vec::with_capacity(dotenv_vars.len() + stored_env_vec.len() + system_env.len());
            // Add dotenv variables first (highest priority)
            for (key, value) in &dotenv_vars {
                temp_env.push(format!("{}={}", key, value));
            }
            // Then add stored environment
            temp_env.extend(stored_env_vec);
            // Finally add system environment
            temp_env.extend(system_env);

            let result = match process_run(ProcessMetadata {
                args: config.args,
                name: name.clone(),
                shell: config.shell,
                log_path: config.log_path,
                command: script.to_string(),
                env: temp_env,
            }) {
                Ok(result) => result,
                Err(err) => {
                    // Restore working directory before returning
                    if let Some(ref dir) = original_dir {
                        let _ = std::env::set_current_dir(dir);
                    }

                    // When dead=true (crash restart), keep running=true so daemon will retry on next cycle
                    // When dead=false (manual restart), set running=false to stop retrying until user manually restarts
                    if !dead {
                        process.running = false;
                    }
                    process.children = vec![];
                    // Reset PID to 0 to indicate process never successfully started
                    // This prevents handle_restart_failure from marking it as crashed
                    process.pid = 0;
                    process.shell_pid = None;

                    // Increment crash counter for restart failures to count against restart limit
                    // When dead=true (daemon restart): don't increment (daemon already incremented)
                    // When dead=false (manual restart): increment (first time counting this failure)
                    self.handle_restart_failure(id, &name, max_restarts, !dead);
                    // Note: handle_restart_failure sets crashed=true, so we don't need to set it here

                    // Save state to persist counter increments and state changes
                    self.save_after_restart_failure(dead);

                    log::error!("Failed to restart process '{}' (id={}): {}", name, id, err);
                    println!(
                        "{} Failed to restart process '{}' (id={}): {}",
                        *helpers::FAIL,
                        name,
                        id,
                        err
                    );
                    return self;
                }
            };

            // Check for duplicate PIDs before updating process
            // This prevents tracking the same process multiple times after restart
            let (has_duplicate, error_msg) = check_duplicate_pid(
                &self.list,
                id,
                result.pid,
                result.shell_pid,
            );
            
            if has_duplicate {
                log::warn!(
                    "[process] Duplicate PID detected on restart: process '{}' (id={}). {}",
                    name,
                    id,
                    error_msg
                );
                println!(
                    "{} Process '{}' (id={}) restart aborted: {}",
                    *helpers::FAIL,
                    name,
                    id,
                    error_msg
                );
                // Restore working directory before returning
                if let Some(ref dir) = original_dir {
                    let _ = std::env::set_current_dir(dir);
                }
                return self;
            }

            // Get mutable reference to process after duplicate check
            let process = self.process(id);

            process.pid = result.pid;
            process.shell_pid = result.shell_pid;
            process.session_id = result.session_id;
            process.process_start_time = result.start_time;
            process.is_process_tree = result.shell_pid.is_some();
            process.running = true;
            process.started = Utc::now();
            // Clear crashed flag after successful restart
            // This allows the daemon to properly detect if the process crashes again
            process.crash.crashed = false;
            // Clear manual_stop flag when process is started/restarted
            process.manual_stop = false;
            process.last_action_at = Utc::now();

            // Discover children immediately after starting the process
            // This prevents race conditions where the parent exits before the daemon
            // can discover the children in its monitoring loop.
            // Poll for children with shorter intervals rather than one long sleep,
            // so we can detect children as soon as they appear.
            const MAX_DISCOVERY_TIME_MS: u64 = 600;
            const POLL_INTERVAL_MS: u64 = 50;
            let mut elapsed_ms = 0;

            while elapsed_ms < MAX_DISCOVERY_TIME_MS {
                thread::sleep(Duration::from_millis(POLL_INTERVAL_MS));
                elapsed_ms += POLL_INTERVAL_MS;

                let discovered_children = process_find_children(result.pid);
                if !discovered_children.is_empty() {
                    process.children = discovered_children;
                    log::info!(
                        "Discovered {} child process(es) after {}ms: {:?}",
                        process.children.len(),
                        elapsed_ms,
                        process.children
                    );
                    break;
                }
            }

            // If no children found after polling, that's OK - the daemon will discover them later
            if process.children.is_empty() {
                log::debug!(
                    "No children discovered after {}ms for process {}",
                    elapsed_ms,
                    result.pid
                );
            }

            // Merge .env variables into the stored environment (dotenv takes priority)
            let mut updated_env: Env = env::vars().collect();
            updated_env.extend(dotenv_vars);
            process.env.extend(updated_env);

            // Don't reset crash counter - keep it to preserve crash history
            // The daemon will reset it automatically after the process runs successfully
            // for the grace period (1 second), which provides better visibility into
            // process stability over time.

            // Restore the original working directory to avoid affecting the daemon
            if let Some(dir) = original_dir {
                if let Err(err) = std::env::set_current_dir(&dir) {
                    log::warn!("Failed to restore working directory after restart: {}", err);
                }
            }

            // Timestamp file was already created at the beginning of this method
            // to prevent race conditions with the daemon during the entire restart operation.

            // Save state after successful restart to persist changes
            // Use save_direct() when called from daemon (dead=true) to avoid serialization
            // that would lose fields marked with #[serde(skip)] like the restart counter
            if dead {
                self.save_direct();
            } else {
                self.save();
            }
        }

        return self;
    }

    pub fn reload(&mut self, id: usize, dead: bool, increment_counter: bool) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::reload(remote, id) {
                crashln!(
                    "{} Failed to reload process {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            let process = self.process(id);
            let full_config = config::read();
            let config = full_config.runner;
            let max_restarts = full_config.daemon.restarts;
            let Process {
                path,
                script,
                name,
                env,
                watch: _,
                max_memory: _,
                ..
            } = process.clone();

            // Save the current working directory so we can restore it after reload
            let original_dir = std::env::current_dir().ok();

            // Increment restart counter based on parameters:
            // - dead=true (daemon auto-restart): don't increment (daemon already incremented)
            // - dead=false with increment_counter=true (manual reload): increment
            // - dead=false with increment_counter=false (not currently used): don't increment
            if !dead && increment_counter {
                process.restarts += 1;
            }

            if let Err(err) = std::env::set_current_dir(&path) {
                // Restore working directory before returning
                if let Some(ref dir) = original_dir {
                    let _ = std::env::set_current_dir(dir);
                }

                // When dead=true (crash reload), keep running=true so daemon will retry on next cycle
                // When dead=false (manual reload), set running=false to stop retrying until user manually reloads
                if !dead {
                    process.running = false;
                }
                process.children = vec![];
                // Reset PID to 0 to indicate process never successfully started
                // This prevents handle_restart_failure from marking it as crashed
                process.pid = 0;
                process.shell_pid = None;

                // Increment crash counter for reload failures to count against restart limit
                // When dead=true (daemon reload): don't increment (daemon already incremented)
                // When dead=false (manual reload): increment (first time counting this failure)
                self.handle_restart_failure(id, &name, max_restarts, !dead);
                // Note: handle_restart_failure sets crashed=true, so we don't need to set it here

                // Save state to persist counter increments and state changes
                self.save_after_restart_failure(dead);

                log::error!(
                    "Failed to set working directory {:?} for process {} during reload: {}",
                    path,
                    name,
                    err
                );
                println!(
                    "{} Failed to set working directory {:?}\nError: {:#?}",
                    *helpers::FAIL,
                    path,
                    err
                );
                return self;
            }

            // Load environment variables from .env file
            let dotenv_vars = load_dotenv(&path);
            let system_env = unix::env();

            // Prepare process environment with dotenv variables having priority
            let stored_env_vec: Vec<String> = env
                .iter()
                .map(|(key, value)| format!("{}={}", key, value))
                .collect();
            let mut temp_env =
                Vec::with_capacity(dotenv_vars.len() + stored_env_vec.len() + system_env.len());
            // Add dotenv variables first (highest priority)
            for (key, value) in &dotenv_vars {
                temp_env.push(format!("{}={}", key, value));
            }
            // Then add stored environment
            temp_env.extend(stored_env_vec);
            // Finally add system environment
            temp_env.extend(system_env);

            // Start new process first
            let result = match process_run(ProcessMetadata {
                args: config.args,
                name: name.clone(),
                shell: config.shell,
                log_path: config.log_path,
                command: script.to_string(),
                env: temp_env,
            }) {
                Ok(result) => result,
                Err(err) => {
                    // Restore working directory before returning
                    if let Some(ref dir) = original_dir {
                        let _ = std::env::set_current_dir(dir);
                    }

                    // When dead=true (crash reload), keep running=true so daemon will retry on next cycle
                    // When dead=false (manual reload), set running=false to stop retrying until user manually reloads
                    if !dead {
                        process.running = false;
                    }
                    process.children = vec![];
                    // Reset PID to 0 to indicate process never successfully started
                    // This prevents handle_restart_failure from marking it as crashed
                    process.pid = 0;
                    process.shell_pid = None;

                    // Increment crash counter for reload failures to count against restart limit
                    // When dead=true (daemon reload): don't increment (daemon already incremented)
                    // When dead=false (manual reload): increment (first time counting this failure)
                    self.handle_restart_failure(id, &name, max_restarts, !dead);
                    // Note: handle_restart_failure sets crashed=true, so we don't need to set it here

                    // Save state to persist counter increments and state changes
                    self.save_after_restart_failure(dead);

                    log::error!("Failed to reload process '{}' (id={}): {}", name, id, err);
                    println!(
                        "{} Failed to reload process '{}' (id={}): {}",
                        *helpers::FAIL,
                        name,
                        id,
                        err
                    );
                    return self;
                }
            };

            // Store old PID before updating
            let old_pid = process.pid;
            let old_children = process.children.clone();

            // Update process with new PID
            process.pid = result.pid;
            process.shell_pid = result.shell_pid;
            process.session_id = result.session_id;
            process.process_start_time = result.start_time;
            process.is_process_tree = result.shell_pid.is_some();
            process.running = true;
            process.children = vec![];
            process.started = Utc::now();
            // Clear crashed flag after successful reload
            // This allows the daemon to properly detect if the process crashes again
            process.crash.crashed = false;
            // Clear manual_stop flag when process is reloaded
            process.manual_stop = false;
            process.last_action_at = Utc::now();

            // Merge .env variables into the stored environment (dotenv takes priority)
            let mut updated_env: Env = env::vars().collect();
            updated_env.extend(dotenv_vars);
            process.env.extend(updated_env);

            // Don't reset crash counter - keep it to preserve crash history
            // The daemon will reset it automatically after the process runs successfully
            // for the grace period (1 second), which provides better visibility into
            // process stability over time.

            // Now stop the old process after the new one is running
            kill_children(old_children);
            if let Err(err) = process_stop(old_pid) {
                log::warn!("Failed to stop old process during reload: {err}");
            }

            // Wait for old process to fully terminate to release any held resources
            if !wait_for_process_termination(old_pid) {
                log::warn!(
                    "Old process {} did not terminate within timeout during reload",
                    old_pid
                );
            }

            // Restore the original working directory
            if let Some(dir) = original_dir {
                if let Err(err) = std::env::set_current_dir(&dir) {
                    log::warn!("Failed to restore working directory after reload: {}", err);
                }
            }

            // Create timestamp file for manual reloads (not daemon reloads) to prevent
            // daemon from immediately marking the process as crashed during startup
            // This gives the process time to initialize before daemon monitoring kicks in
            // Write with fsync to ensure timestamp is durably written before daemon checks
            if !dead {
                if let Err(e) = write_action_timestamp(id) {
                    log::warn!(
                        "Failed to create action timestamp file for process {}: {}",
                        id,
                        e
                    );
                }
            }

            // Save state after successful reload to persist changes
            // Use save_direct() when called from daemon (dead=true) to avoid serialization
            // that would lose fields marked with #[serde(skip)] like the restart counter
            if dead {
                self.save_direct();
            } else {
                self.save();
            }
        }

        return self;
    }

    /// Direct process removal without daemon delegation
    /// This is called by the socket handler to avoid infinite recursion
    /// DO NOT call this directly from CLI - use remove() instead
    pub fn remove_direct_internal(&mut self, id: usize) {
        // Get PID info before removing from list
        let pid = self.info(id).map(|p| p.pid).unwrap_or(0);
        let shell_pid = self.info(id).and_then(|p| p.shell_pid);
        let children = self
            .info(id)
            .map(|p| p.children.clone())
            .unwrap_or_default();

        // Mark as stopped first to prevent auto-restart during removal
        // This is important if daemon is running and monitoring processes
        if self.exists(id) {
            self.process(id).running = false;
            self.save();
        }

        // Remove from list
        self.list.remove(&id);
        self.compact(); // Compact IDs after removal
        self.save();
        // Persist in-memory deletions immediately to permanent storage
        // so that deleted processes do not reappear after a restart/restore.
        dump::commit_memory();

        // Now kill the actual process using the saved PID info
        if pid > 0 {
            kill_children(children);
            let _ = process_stop(pid);

            // Wait for process termination
            if !wait_for_process_termination(pid) {
                log::warn!(
                    "Process {} did not terminate within timeout during remove",
                    pid
                );
            }

            // Remove child handle from global state if it exists
            let handle_pid = shell_pid.unwrap_or(pid);
            if let Some((_, handle)) = PROCESS_HANDLES.remove(&handle_pid) {
                if let Ok(mut child) = handle.lock() {
                    let _ = child.wait();
                }
            }
        }
    }

    pub fn remove(&mut self, id: usize) {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::remove(remote, id) {
                crashln!(
                    "{} Failed to stop remove {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            // Check if daemon is running - if so, delegate to daemon via socket
            // This ensures daemon's monitoring loop sees the removal immediately
            let socket_path = global!("opm.socket");
            if crate::socket::is_daemon_running(&socket_path) {
                match crate::socket::send_request(
                    &socket_path,
                    crate::socket::SocketRequest::RemoveProcess(id),
                ) {
                    Ok(crate::socket::SocketResponse::Success) => {
                        // Reload state to reflect the removal
                        *self = Runner::new();
                        return;
                    }
                    Ok(crate::socket::SocketResponse::Error(msg)) => {
                        crashln!("{} Failed to remove process {id}: {msg}", *helpers::FAIL);
                    }
                    Ok(_) => {
                        crashln!("{} Unexpected response from daemon", *helpers::FAIL);
                    }
                    Err(_) => {
                        // Fall through to direct removal if socket communication fails
                    }
                }
            }

            // Direct removal (daemon not running or socket failed)
            self.remove_direct_internal(id);
        }
    }

    /// Compact process IDs by reindexing all processes to fill gaps
    /// Example: if processes 0, 2, 5 exist, they become 0, 1, 2
    pub fn compact(&mut self) {
        if self.remote.is_some() {
            return; // Don't compact remote processes
        }

        // If list is empty, reset ID counter to 0
        if self.list.is_empty() {
            self.id = id::Id::new(0);
            log::debug!("[compact] Empty list, reset ID counter to 0");
            return;
        }

        // Check if compaction is needed by comparing keys to sequential range
        let keys: Vec<usize> = self.list.keys().copied().collect();
        let expected_keys: Vec<usize> = (0..keys.len()).collect();
        if keys == expected_keys {
            // Already compact, just ensure ID counter is correct
            self.id = id::Id::new(keys.len());
            log::debug!(
                "[compact] Already compact, IDs: {:?}, next ID: {}",
                keys,
                keys.len()
            );
            return;
        }

        log::debug!(
            "[compact] Compacting IDs from {:?} to 0..{}",
            keys,
            keys.len()
        );

        // BTreeMap is already sorted, so we can use into_iter() directly
        // Extract all processes by replacing the list with an empty one
        let old_list = std::mem::replace(&mut self.list, BTreeMap::new());

        // Re-insert with new sequential IDs starting from 0
        // BTreeMap::into_iter() yields items in sorted key order
        for (new_id, (old_id, mut process)) in old_list.into_iter().enumerate() {
            // Update the process ID to match the new ID
            process.id = new_id;
            self.list.insert(new_id, process);
            log::debug!("[compact] Remapped process ID {} -> {}", old_id, new_id);
        }

        // Reset the ID counter to the next available ID
        self.id = id::Id::new(self.list.len());
        log::debug!(
            "[compact] Compaction complete, next ID: {}",
            self.list.len()
        );
    }

    pub fn set_id(&mut self, id: id::Id) {
        self.id = id;
        self.id.next();
        self.save();
    }

    pub fn set_status(&mut self, id: usize, status: Status) {
        self.process(id).running = status.to_bool();
        self.save();
    }

    pub fn items(&self) -> BTreeMap<usize, Process> {
        self.list.clone()
    }

    pub fn items_mut(&mut self) -> &mut BTreeMap<usize, Process> {
        &mut self.list
    }

    /// Get an iterator over the process IDs without cloning the entire process map
    /// This is more efficient than calling items().keys() when you only need the IDs
    pub fn process_ids(&self) -> impl Iterator<Item = usize> + '_ {
        self.list.keys().copied()
    }

    /// Save runner state to memory cache (fast, in-memory storage)
    /// Use save_permanent() for explicit saves to disk
    pub fn save(&self) {
        if self.remote.is_none() {
            dump::write_memory(&self);
        }
    }

    /// Save runner state directly to memory cache without using socket
    /// This is used by the daemon itself to avoid serialization/deserialization
    /// that would lose fields marked with #[serde(skip)] like the restart counter
    pub fn save_direct(&self) {
        if self.remote.is_none() {
            dump::write_memory_direct(&self);
        }
    }

    /// Freeze a process to prevent auto-restart for a specified duration
    /// This is used during edit/delete operations to avoid conflicts with daemon
    pub fn freeze(&mut self, id: usize, duration_secs: i64) {
        if let Some(process) = self.list.get_mut(&id) {
            process.frozen_until = Some(Utc::now() + chrono::Duration::seconds(duration_secs));
            self.save();
            log::debug!("Process {} frozen for {} seconds", id, duration_secs);
        } else {
            log::warn!("Attempted to freeze non-existent process {}", id);
        }
    }

    /// Unfreeze a process to allow auto-restart again
    pub fn unfreeze(&mut self, id: usize) {
        if let Some(process) = self.list.get_mut(&id) {
            process.frozen_until = None;
            self.save();
            log::debug!("Process {} unfrozen", id);
        } else {
            log::warn!("Attempted to unfreeze non-existent process {}", id);
        }
    }

    /// Check if a process is currently frozen (auto-restart paused)
    pub fn is_frozen(&self, id: usize) -> bool {
        if let Some(process) = self.list.get(&id) {
            if let Some(frozen_until) = process.frozen_until {
                return Utc::now() < frozen_until;
            }
        }
        false
    }

    /// Save runner state to permanent dump file (used only by explicit 'opm save' command)
    pub fn save_permanent(&self) {
        if self.remote.is_none() {
            // Merge memory into permanent and clear memory
            dump::commit_memory();
        }
    }

    #[deprecated(note = "Use save() instead - it now writes directly to permanent storage")]
    pub fn save_temp(&self) {
        // Deprecated: now save directly to memory cache
        self.save();
    }

    pub fn count(&mut self) -> usize {
        self.list().count()
    }

    pub fn is_empty(&self) -> bool {
        self.list.is_empty()
    }

    pub fn exists(&self, id: usize) -> bool {
        self.list.contains_key(&id)
    }

    pub fn info(&self, id: usize) -> Option<&Process> {
        self.list.get(&id)
    }

    pub fn try_info(&self, id: usize) -> &Process {
        self.list
            .get(&id)
            .unwrap_or_else(|| crashln!("{} Process ({id}) not found", *helpers::FAIL))
    }

    pub fn size(&self) -> Option<&usize> {
        self.list.iter().map(|(k, _)| k).max()
    }

    pub fn list<'l>(&'l mut self) -> impl Iterator<Item = (&'l usize, &'l mut Process)> {
        self.list.iter_mut().map(|(k, v)| (k, v))
    }

    pub fn process(&mut self, id: usize) -> &mut Process {
        self.list
            .get_mut(&id)
            .unwrap_or_else(|| crashln!("{} Process ({id}) not found", *helpers::FAIL))
    }

    pub fn pid(&self, id: usize) -> i64 {
        self.list
            .get(&id)
            .unwrap_or_else(|| crashln!("{} Process ({id}) not found", *helpers::FAIL))
            .pid
    }

    pub fn get(self, id: usize) -> ProcessWrapper {
        ProcessWrapper {
            id,
            runner: Arc::new(Mutex::new(self)),
        }
    }

    pub fn set_crashed(&mut self, id: usize) -> &mut Self {
        self.process(id).crash.crashed = true;
        // Keep running=true so daemon will attempt to restart the process
        // Don't set running=false here - that should only happen when we give up after max retries
        return self;
    }

    pub fn set_env(&mut self, id: usize, env: Env) -> &mut Self {
        self.process(id).env.extend(env);
        return self;
    }

    pub fn clear_env(&mut self, id: usize) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::clear_env(remote, id) {
                crashln!(
                    "{} Failed to clear environment on {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            self.process(id).env = BTreeMap::new();
        }

        return self;
    }

    pub fn set_children(&mut self, id: usize, children: Vec<i64>) -> &mut Self {
        self.process(id).children = children;
        return self;
    }

    pub fn new_crash(&mut self, id: usize) -> &mut Self {
        self.process(id).restarts += 1;
        return self;
    }

    /// Save state after restart/reload failure to persist counter increments and state changes
    ///
    /// # Arguments
    /// * `dead` - True if this is a daemon-initiated restart (process already dead/crashed),
    ///           False if this is a user-initiated manual restart/reload.
    ///           When true, uses save_direct() to preserve #[serde(skip)] fields like restart counter.
    ///           When false, uses save() for full serialization.
    fn save_after_restart_failure(&mut self, dead: bool) {
        if dead {
            self.save_direct();
        } else {
            self.save();
        }
    }

    /// Handle restart/reload failure by optionally incrementing restart counter and checking limit
    /// Sets running=false if the limit is reached or exceeded
    ///
    /// # Arguments
    /// * `increment_counter` - Whether to increment restart counter. Set to false if counter was already incremented by daemon.
    fn handle_restart_failure(
        &mut self,
        id: usize,
        process_name: &str,
        max_restarts: u64,
        increment_counter: bool,
    ) {
        let process = self.process(id);

        // Only increment if not already incremented by caller (e.g., daemon)
        if increment_counter {
            process.restarts += 1;
        }

        // Only mark as crashed if the process was actually running before (had a valid PID)
        // Processes that never successfully started (pid <= 0) should remain in stopped state
        //
        // The PID indicates whether a process ran in this session:
        // - pid > 0: Process was running (or restored and successfully restarted), failure is a crash
        // - pid = 0: Process never started in this session (restored but not started, or explicitly stopped)
        //            Failure to start is not a crash, process remains in stopped state
        if process.pid > 0 {
            process.crash.crashed = true;
        }

        // Check if we've reached or exceeded max restart limit
        if process.restarts >= max_restarts {
            process.running = false;
            log::error!(
                "Process {} reached max restart attempts due to repeated failures",
                process_name
            );
        }
    }

    pub fn stop(&mut self, id: usize) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::stop(remote, id) {
                crashln!(
                    "{} Failed to stop process {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            let process_to_stop = self.process(id);
            let pid_to_check = process_to_stop.pid;
            let shell_pid = process_to_stop.shell_pid;
            let children = process_to_stop.children.clone();

            // CRITICAL: Set manual_stop flag BEFORE killing the process
            // This prevents a race condition where the daemon detects the process death
            // before seeing the manual_stop flag, causing it to restart the process
            let process = self.process(id);
            process.running = false;
            process.crash.crashed = false;
            process.last_action_at = Utc::now();
            // Set manual_stop flag to indicate user-initiated stop
            // This prevents daemon from treating the exit as a crash
            process.manual_stop = true;
            // Save state BEFORE killing to ensure daemon sees the flag first
            self.save();

            // Now kill the process - daemon will see manual_stop=true if it checks
            kill_children(children);
            let _ = process_stop(pid_to_check); // Continue even if stopping fails

            // waiting until Process is terminated
            if !wait_for_process_termination(pid_to_check) {
                log::warn!(
                    "Process {} did not terminate within timeout during stop",
                    pid_to_check
                );
            }

            // Remove child handle from global state if it exists
            // Use shell_pid if available, otherwise try regular pid
            let handle_pid = shell_pid.unwrap_or(pid_to_check);
            if let Some((_, handle)) = PROCESS_HANDLES.remove(&handle_pid) {
                // Wait for the child process to complete and reap it
                if let Ok(mut child) = handle.lock() {
                    if let Err(e) = child.wait() {
                        log::warn!("Failed to wait for child process {}: {}", handle_pid, e);
                    }
                }
            }

            // Clear PIDs after process is fully stopped
            let process = self.process(id);
            // Keep restarts counter to preserve restart history - only reset via reset_counters()
            process.children = vec![];
            // Set PID to 0 to indicate no valid PID and prevent monitor from treating this as a crash
            process.pid = 0;
            // Reset shell_pid to None to prevent monitor from treating this as a crash
            process.shell_pid = None;

            // Save final state after process is fully terminated
            self.save();
        }

        return self;
    }

    pub fn flush(&mut self, id: usize) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::flush(remote, id) {
                crashln!(
                    "{} Failed to flush process {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            self.process(id).logs().flush();
        }

        return self;
    }

    pub fn rename(&mut self, id: usize, name: String) -> &mut Self {
        if let Some(remote) = &self.remote {
            if let Err(err) = http::rename(remote, id, name) {
                crashln!(
                    "{} Failed to rename process {id}\nError: {:#?}",
                    *helpers::FAIL,
                    err
                );
            };
        } else {
            self.process(id).name = name;
        }

        return self;
    }

    pub fn watch(&mut self, id: usize, path: &str, enabled: bool) -> &mut Self {
        let process = self.process(id);
        process.watch = Watch {
            enabled,
            path: string!(path),
            hash: ternary!(enabled, hash::create(process.path.join(path)), string!("")),
        };

        return self;
    }

    pub fn reset_counters(&mut self, id: usize) -> &mut Self {
        let process = self.process(id);
        process.restarts = 0;
        process.crash.crashed = false;
        process.last_action_at = Utc::now();
        return self;
    }

    pub fn find(&self, name: &str, server_name: &String) -> Option<usize> {
        let mut runner = self.clone();

        if !matches!(&**server_name, "internal" | "local") {
            let Some(servers) = config::servers().servers else {
                crashln!("{} Failed to read servers", *helpers::FAIL)
            };

            if let Some(server) = servers.get(server_name) {
                runner = match Runner::connect(server_name.clone(), server.get(), false) {
                    Some(remote) => remote,
                    None => crashln!(
                        "{} Failed to connect (name={server_name}, address={})",
                        *helpers::FAIL,
                        server.address
                    ),
                };
            } else {
                crashln!("{} Server '{server_name}' does not exist", *helpers::FAIL)
            };
        }

        runner
            .list
            .iter()
            .find(|(_, p)| p.name == name)
            .map(|(id, _)| *id)
    }

    /// Helper method to build ProcessItem from Process
    fn build_process_item(&self, id: usize, item: &Process) -> ProcessItem {
        let mut memory_usage: Option<MemoryInfo> = None;
        let mut cpu_percent: Option<f64> = None;

        // Use new_fast() to avoid CPU measurement delays for list view
        // For shell scripts, try shell_pid first to capture the entire process tree
        let mut pid_for_monitoring = item.shell_pid.unwrap_or(item.pid);
        let mut process_result = unix::NativeProcess::new_fast(pid_for_monitoring as u32);

        // If shell_pid fails (process exited), try the actual script pid
        if process_result.is_err() && item.shell_pid.is_some() {
            pid_for_monitoring = item.pid;
            process_result = unix::NativeProcess::new_fast(pid_for_monitoring as u32);
        }

        if let Ok(process) = process_result {
            if let Ok(_mem_info_native) = process.memory_info() {
                cpu_percent = Some(get_process_cpu_usage_with_children_fast(pid_for_monitoring));
                memory_usage = get_process_memory_with_children(pid_for_monitoring);
            }
        }

        let cpu_percent = match cpu_percent {
            Some(percent) => format!("{:.2}%", percent),
            None => string!("0.00%"),
        };

        let memory_usage = match memory_usage {
            Some(usage) => helpers::format_memory(usage.rss),
            None => string!("0b"),
        };

        // Check if process is alive by checking root PID, shell PID (if present), and all tracked descendants
        // This ensures background shell processes with living children are not marked as crashed
        let any_descendant_alive = is_any_descendant_alive(item.pid, &item.children)
            || item
                .shell_pid
                .map_or(false, |pid| is_any_descendant_alive(pid, &item.children));

        let process_actually_running = item.running && any_descendant_alive;

        let crash_detection_enabled = config::read().daemon.crash_detection;
        let status = if process_actually_running {
            string!("online")
        } else if item.running {
            // Process is marked as running but PID is not alive.
            // Use longer grace period to account for slow-starting processes
            // and to avoid false crash reports during daemon restart cycles
            let grace_period = chrono::Duration::seconds(STATUS_GRACE_PERIOD_SECS);

            if item.pid == 0 {
                // PID is 0, which means either:
                // 1. New/restored process waiting for daemon to start it, OR
                // 2. Process just crashed and daemon is about to restart it
                // In both cases, show "starting" since daemon will handle it within the monitoring interval
                string!("starting")
            } else {
                if !crash_detection_enabled {
                    string!("stopped")
                } else {
                    // Calculate time since start only when needed (not for pid=0 case)
                    let time_since_start = Utc::now().signed_duration_since(item.started);

                    if time_since_start < grace_period {
                        // PID is non-zero but process is dead, and we're still within grace period.
                        // This could be a very quick crash or the process is still initializing.
                        // Show "starting" to avoid false crash reports.
                        string!("starting")
                    } else {
                        // Grace period has passed and process is still dead - it's officially crashed.
                        string!("crashed")
                    }
                }
            }
        } else {
            match item.crash.crashed {
                true => string!("crashed"),
                false => string!("stopped"),
            }
        };

        // Use OS-level uptime from sysinfo for accurate uptime calculation
        let uptime = if process_actually_running {
            let uptime_secs = get_process_uptime_sysinfo(item.pid);
            if uptime_secs > 0 {
                helpers::format_uptime_seconds(uptime_secs)
            } else {
                string!("0s")
            }
        } else {
            string!("0s")
        };

        ProcessItem {
            id,
            status,
            pid: item.pid,
            cpu: cpu_percent,
            mem: memory_usage,
            restarts: item.restarts,
            name: item.name.clone(),
            start_time: item.started,
            watch_path: item.watch.path.clone(),
            uptime,
            agent_id: item.agent_id.clone(),
            agent_name: None,
            agent_api_endpoint: None,
        }
    }

    pub fn fetch(&self) -> Vec<ProcessItem> {
        let mut processes: Vec<ProcessItem> = Vec::new();

        for (id, item) in self.items() {
            processes.push(self.build_process_item(id, &item));
        }

        return processes;
    }

    /// Fetch processes filtered by agent ID
    pub fn fetch_by_agent(&self, agent_id: &str) -> Vec<ProcessItem> {
        let mut processes: Vec<ProcessItem> = Vec::new();

        for (id, item) in self.items() {
            // Only include processes that belong to the specified agent
            if item.agent_id.as_deref() == Some(agent_id) {
                processes.push(self.build_process_item(id, &item));
            }
        }

        return processes;
    }
}

impl LogInfo {
    pub fn flush(&self) {
        if let Err(err) = File::create(&self.out) {
            log::error!("{err}");
            crashln!(
                "{} Failed to purge logs (path={})",
                *helpers::FAIL,
                self.error
            );
        }

        if let Err(err) = File::create(&self.error) {
            log::error!("{err}");
            crashln!(
                "{} Failed to purge logs (path={})",
                *helpers::FAIL,
                self.error
            );
        }
    }
}

impl Process {
    /// Get a log paths of the process item
    pub fn logs(&self) -> LogInfo {
        let name = self.name.replace(" ", "_");

        LogInfo {
            out: global!("opm.logs.out", name.as_str()),
            error: global!("opm.logs.error", name.as_str()),
        }
    }
}

impl ProcessWrapper {
    /// Stop the process item
    pub fn stop(&mut self) {
        lock!(self.runner).stop(self.id);
    }

    /// Restart the process item
    /// `increment_counter`: whether to increment the restart counter
    pub fn restart(&mut self, increment_counter: bool) {
        lock!(self.runner).restart(self.id, false, increment_counter);
    }

    /// Reload the process item (zero-downtime: starts new process before stopping old one)
    /// `increment_counter`: whether to increment the restart counter
    pub fn reload(&mut self, increment_counter: bool) {
        lock!(self.runner).reload(self.id, false, increment_counter);
    }

    /// Rename the process item
    pub fn rename(&mut self, name: String) {
        lock!(self.runner).rename(self.id, name);
    }

    /// Enable watching a path on the process item
    pub fn watch(&mut self, path: &str) {
        lock!(self.runner).watch(self.id, path, true);
    }

    /// Disable watching on the process item
    pub fn disable_watch(&mut self) {
        lock!(self.runner).watch(self.id, "", false);
    }

    /// Set the process item as crashed
    pub fn crashed(&mut self) {
        lock!(self.runner).restart(self.id, true, true);
    }

    /// Get the borrowed runner reference (lives till program end)
    pub fn get_runner(&mut self) -> &Runner {
        Box::leak(Box::new(lock!(self.runner)))
    }

    /// Append new environment values to the process item
    pub fn set_env(&mut self, env: Env) {
        lock!(self.runner).set_env(self.id, env);
    }

    /// Clear environment values of the process item
    pub fn clear_env(&mut self) {
        lock!(self.runner).clear_env(self.id);
    }

    /// Reset restart and crash counters of the process item
    pub fn reset_counters(&mut self) {
        lock!(self.runner).reset_counters(self.id);
    }

    /// Get a json dump of the process item
    pub fn fetch(&self) -> ItemSingle {
        let mut runner = lock!(self.runner);

        let item = runner.process(self.id);
        let full_config = config::read();
        let config = full_config.runner;

        let crash_detection_enabled = config::read().daemon.crash_detection;
        // Check if process actually exists before reporting as online
        // Use descendants and shell PID for shell-wrapped/backgrounded processes
        let any_descendant_alive = is_any_descendant_alive(item.pid, &item.children)
            || item
                .shell_pid
                .map_or(false, |pid| is_any_descendant_alive(pid, &item.children));
        let process_actually_running = item.running && any_descendant_alive;

        let mut memory_usage: Option<MemoryInfo> = None;
        let mut cpu_percent: Option<f64> = None;

        // Only fetch CPU and memory stats if process is actually running
        // Stopped or crashed processes should always show None (which displays as 0)
        if process_actually_running {
            // For shell scripts, try shell_pid first to capture the entire process tree
            // If shell_pid process has exited, fall back to the actual script pid
            let mut pid_for_monitoring = item.shell_pid.unwrap_or(item.pid);
            let mut process_result = unix::NativeProcess::new(pid_for_monitoring as u32);

            // If shell_pid fails (process exited), try the actual script pid
            if process_result.is_err() && item.shell_pid.is_some() {
                pid_for_monitoring = item.pid;
                process_result = unix::NativeProcess::new(pid_for_monitoring as u32);
            }

            if let Ok(process) = process_result {
                if let Ok(_mem_info_native) = process.memory_info() {
                    cpu_percent = Some(get_process_cpu_usage_with_children_from_process(
                        &process,
                        pid_for_monitoring,
                    ));
                    memory_usage = get_process_memory_with_children(pid_for_monitoring);
                }
            }
        }

        let status = if process_actually_running {
            string!("online")
        } else if item.running {
            // Process is marked as running but PID is not alive.
            // Use grace period to account for slow-starting processes and restart windows
            let grace_period = chrono::Duration::seconds(STATUS_GRACE_PERIOD_SECS);

            if item.pid == 0 {
                // PID is 0 - process is waiting to be started or restarted by daemon
                string!("starting")
            } else {
                if !crash_detection_enabled {
                    string!("stopped")
                } else {
                    // Calculate time since start only when needed (not for pid=0 case)
                    let time_since_start = Utc::now().signed_duration_since(item.started);

                    if time_since_start < grace_period {
                        // Within grace period - still initializing
                        string!("starting")
                    } else {
                        // Grace period expired - process has crashed
                        string!("crashed")
                    }
                }
            }
        } else {
            if crash_detection_enabled && item.crash.crashed {
                string!("crashed")
            } else {
                string!("stopped")
            }
        };

        // Use OS-level uptime from sysinfo for accurate uptime calculation
        // Only count uptime when the process is actually running
        // Crashed or stopped processes should show "0s" uptime
        let uptime = if process_actually_running {
            let uptime_secs = get_process_uptime_sysinfo(item.pid);
            if uptime_secs > 0 {
                helpers::format_uptime_seconds(uptime_secs)
            } else {
                string!("0s")
            }
        } else {
            string!("0s")
        };

        ItemSingle {
            info: Info {
                status,
                id: item.id,
                pid: item.pid,
                name: item.name.clone(),
                path: item.path.clone(),
                children: item.children.clone(),
                uptime,
                command: format!(
                    "{} {} '{}'",
                    config.shell,
                    config.args.join(" "),
                    item.script.clone()
                ),
            },
            stats: Stats {
                cpu_percent,
                memory_usage,
                restarts: item.restarts,
                start_time: item.started.timestamp_millis(),
            },
            watch: Watch {
                enabled: item.watch.enabled,
                hash: item.watch.hash.clone(),
                path: item.watch.path.clone(),
            },
            log: Log {
                out: item.logs().out,
                error: item.logs().error,
            },
            raw: Raw {
                running: item.running,
                crashed: item.crash.crashed,
                crashes: item.restarts,
            },
        }
    }
}

/// Get the CPU usage percentage of the process
pub fn get_process_cpu_usage_percentage(pid: i64) -> f64 {
    match unix::NativeProcess::new(pid as u32) {
        Ok(process) => match process.cpu_percent() {
            Ok(cpu_percent) => cpu_percent,
            Err(_) => 0.0,
        },
        Err(_) => 0.0,
    }
}

/// Get the CPU usage percentage of the process (fast version without delay)
pub fn get_process_cpu_usage_percentage_fast(pid: i64) -> f64 {
    match unix::NativeProcess::new_fast(pid as u32) {
        Ok(process) => match process.cpu_percent() {
            Ok(cpu_percent) => cpu_percent,
            Err(_) => 0.0,
        },
        Err(_) => 0.0,
    }
}

/// Get the total CPU usage percentage of the process and its children
/// If parent_process is provided, it will be used instead of creating a new one
/// This function uses the parent's CPU measurement (which may have been timed with delay)
/// and fast measurements for children to avoid cumulative delays and ensure consistency
pub fn get_process_cpu_usage_with_children_from_process(
    parent_process: &unix::NativeProcess,
    pid: i64,
) -> f64 {
    let parent_cpu = match parent_process.cpu_percent() {
        Ok(cpu_percent) => cpu_percent,
        Err(_) => 0.0,
    };

    let children = process_find_children(pid);

    // Use fast CPU calculation for children to avoid multiple delays
    // The parent already used a timed measurement, so children should use fast measurements
    // for consistency and to prevent cumulative delays (N children = N * 100ms)
    let children_cpu: f64 = children
        .iter()
        .map(|&child_pid| get_process_cpu_usage_percentage_fast(child_pid))
        .sum();

    parent_cpu + children_cpu
}

/// Get the total CPU usage percentage of the process and its children (fast version)
pub fn get_process_cpu_usage_with_children_fast(pid: i64) -> f64 {
    let parent_cpu = get_process_cpu_usage_percentage_fast(pid);
    let children = process_find_children(pid);

    let children_cpu: f64 = children
        .iter()
        .map(|&child_pid| get_process_cpu_usage_percentage_fast(child_pid))
        .sum();

    parent_cpu + children_cpu
}

/// Get the total CPU usage percentage of the process and its children
/// Uses timed measurement for parent and fast measurements for children
/// to avoid cumulative delays while maintaining accurate parent measurement
pub fn get_process_cpu_usage_with_children(pid: i64) -> f64 {
    let parent_cpu = get_process_cpu_usage_percentage(pid);
    let children = process_find_children(pid);

    // Use fast CPU calculation for children to avoid multiple delays
    // The parent already used a timed measurement, so children should use fast measurements
    // for consistency and to prevent cumulative delays (N children = N * 100ms)
    let children_cpu: f64 = children
        .iter()
        .map(|&child_pid| get_process_cpu_usage_percentage_fast(child_pid))
        .sum();

    parent_cpu + children_cpu
}

/// Get recursive CPU/Memory aggregation for entire process tree using sysinfo
/// This is the PM2-style aggregation that shows total resources for bash wrappers
/// Returns (cpu_percent, rss_bytes, vms_bytes) or None if process not found
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn get_aggregate_process_tree_usage_sysinfo(root_pid: i64) -> Option<(f64, u64, u64)> {
    use std::collections::HashSet;
    use sysinfo::{ProcessRefreshKind, ProcessesToUpdate, System};

    if root_pid <= 0 {
        return None;
    }

    let mut system = System::new();
    system.refresh_processes_specifics(ProcessesToUpdate::All, true, ProcessRefreshKind::new());

    let mut total_cpu: f64 = 0.0;
    let mut total_rss: u64 = 0;
    let mut total_vms: u64 = 0;
    let mut found_root = false;

    // Build parent-child map for recursive traversal
    let mut parent_map: std::collections::HashMap<i64, Vec<i64>> = std::collections::HashMap::new();
    for (pid, process) in system.processes() {
        let pid_i64 = pid.as_u32() as i64;
        if let Some(parent) = process.parent() {
            let parent_i64 = parent.as_u32() as i64;
            parent_map
                .entry(parent_i64)
                .or_insert_with(Vec::new)
                .push(pid_i64);
        }
    }

    // Recursively aggregate resources for root and all descendants
    let mut to_process = vec![root_pid];
    let mut processed = HashSet::new();

    while let Some(current_pid) = to_process.pop() {
        if processed.contains(&current_pid) {
            continue;
        }
        processed.insert(current_pid);

        let sysinfo_pid = sysinfo::Pid::from_u32(current_pid as u32);
        if let Some(process) = system.process(sysinfo_pid) {
            if current_pid == root_pid {
                found_root = true;
            }

            // Aggregate CPU and memory
            total_cpu += process.cpu_usage() as f64;
            total_rss += process.memory();
            total_vms += process.virtual_memory();

            // Add children to processing queue
            if let Some(children) = parent_map.get(&current_pid) {
                for &child_pid in children {
                    to_process.push(child_pid);
                }
            }
        }
    }

    if found_root {
        Some((total_cpu, total_rss, total_vms))
    } else {
        None
    }
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn get_aggregate_process_tree_usage_sysinfo(_root_pid: i64) -> Option<(f64, u64, u64)> {
    None
}

/// Get the total memory usage of the process and its children

/// Get total memory usage of a process tree, including shell wrapper, main process, and all children
/// This aggregates memory from all PIDs associated with a managed process:
/// - shell_pid (if present) and its descendants
/// - main pid and its descendants (if different from shell_pid)
/// - tracked children array
pub fn get_process_tree_memory(
    pid: i64,
    shell_pid: Option<i64>,
    tracked_children: &[i64],
) -> Option<MemoryInfo> {
    let mut total_rss = 0u64;
    let mut total_vms = 0u64;
    let mut processed_pids = HashSet::new();

    // Helper to add memory for a PID and its descendants if not already processed
    // Mutates: total_rss, total_vms, processed_pids
    let mut add_pid_memory = |target_pid: i64| {
        if target_pid <= 0 || processed_pids.contains(&target_pid) {
            return;
        }
        processed_pids.insert(target_pid);

        // Get memory for this PID
        if let Some(mem_info) = unix::NativeProcess::new_fast(target_pid as u32)
            .ok()
            .and_then(|p| p.memory_info().ok())
        {
            total_rss += mem_info.rss();
            total_vms += mem_info.vms();
        }

        // Get memory for all descendants
        let descendants = process_find_children(target_pid);
        for child_pid in descendants {
            // Use insert() return value to check if already processed (single HashSet lookup)
            if processed_pids.insert(child_pid) {
                if let Some(mem_info) = unix::NativeProcess::new_fast(child_pid as u32)
                    .ok()
                    .and_then(|p| p.memory_info().ok())
                {
                    total_rss += mem_info.rss();
                    total_vms += mem_info.vms();
                }
            }
        }
    };

    // Process shell_pid first (if exists)
    if let Some(shell_pid) = shell_pid {
        add_pid_memory(shell_pid);
    }

    // Process main pid (if different from shell_pid)
    if Some(pid) != shell_pid {
        add_pid_memory(pid);
    }

    // Process any explicitly tracked children that weren't already included
    for &child_pid in tracked_children {
        add_pid_memory(child_pid);
    }

    // Return aggregated memory if we found any
    if total_rss > 0 || total_vms > 0 {
        Some(MemoryInfo {
            rss: total_rss,
            vms: total_vms,
        })
    } else {
        None
    }
}

pub fn get_process_memory_with_children(pid: i64) -> Option<MemoryInfo> {
    let parent_memory = unix::NativeProcess::new_fast(pid as u32)
        .ok()?
        .memory_info()
        .ok()
        .map(MemoryInfo::from)?;

    let children = process_find_children(pid);

    let children_memory: (u64, u64) = children
        .iter()
        .filter_map(|&child_pid| {
            unix::NativeProcess::new_fast(child_pid as u32)
                .ok()
                .and_then(|p| p.memory_info().ok())
                .map(|m| (m.rss(), m.vms()))
        })
        .fold((0, 0), |(rss_sum, vms_sum), (rss, vms)| {
            (rss_sum + rss, vms_sum + vms)
        });

    Some(MemoryInfo {
        rss: parent_memory.rss + children_memory.0,
        vms: parent_memory.vms + children_memory.1,
    })
}

/// Stop the process
pub fn process_stop(pid: i64) -> Result<(), String> {
    // Don't attempt to stop invalid PIDs
    // PID 0 sends signal to all processes in current process group (would kill daemon)
    // Negative PIDs send signal to process groups
    if pid <= 0 {
        return Ok(());
    }

    let children = process_find_children(pid);

    // Stop child processes first
    for child_pid in children {
        let _ = kill(Pid::from_raw(child_pid as i32), Signal::SIGTERM);
        // Continue even if stopping child processes fails
    }

    // Stop parent process
    match kill(Pid::from_raw(pid as i32), Signal::SIGTERM) {
        Ok(_) => Ok(()),
        Err(nix::errno::Errno::ESRCH) => {
            // Process already terminated
            Ok(())
        }
        Err(err) => Err(format!("Failed to stop process {}: {:?}", pid, err)),
    }
}

/// Force kill a process and all its children using SIGKILL
/// This is more aggressive than process_stop and ensures termination
/// Used during restore to clean up old processes
pub fn force_kill_process_tree(pid: i64) -> Result<(), String> {
    if pid <= 0 {
        return Ok(());
    }

    // Get all children before killing parent
    let children = process_find_children(pid);

    // Kill all children first with SIGKILL
    for child_pid in children {
        let _ = kill(Pid::from_raw(child_pid as i32), Signal::SIGKILL);
        // Continue even if killing child processes fails
    }

    // Kill parent process with SIGKILL
    match kill(Pid::from_raw(pid as i32), Signal::SIGKILL) {
        Ok(_) => Ok(()),
        Err(nix::errno::Errno::ESRCH) => {
            // Process already terminated
            Ok(())
        }
        Err(err) => Err(format!("Failed to force kill process {}: {:?}", pid, err)),
    }
}

/// Find children of a potentially dead parent by scanning all processes
/// This is more reliable for adoption scenarios than process_find_children,
/// as it works even after the parent process has exited.
pub fn find_children_of_dead_parent(parent_pid: i64) -> Vec<i64> {
    let mut children = Vec::new();
    if parent_pid <= 0 {
        return children;
    }

    if let Ok(processes) = unix::native_processes() {
        for process in processes {
            if let Ok(Some(ppid)) = process.ppid() {
                if ppid as i64 == parent_pid {
                    children.push(process.pid() as i64);
                }
            }
        }
    }
    children
}

/// Search for processes matching a command pattern and return their PIDs
/// Used during restore to find and kill old processes before spawning new ones
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn find_processes_by_command_pattern(pattern: &str) -> Vec<i64> {
    let mut matching_pids = Vec::new();
    
    if pattern.is_empty() {
        return matching_pids;
    }

    if let Ok(processes) = unix::native_processes() {
        for process in processes {
            let pid = process.pid() as i64;
            
            // Try to get command line from /proc or system
            if let Some(cmdline) = unix::get_process_cmdline(pid as i32) {
                if cmdline.contains(pattern) {
                    matching_pids.push(pid);
                }
            }
        }
    }

    matching_pids
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn find_processes_by_command_pattern(_pattern: &str) -> Vec<i64> {
    Vec::new()
}

/// Kill only OPM-managed processes matching command patterns before restore
/// This prevents port conflicts and resource issues while avoiding killing unrelated processes
pub fn kill_old_processes_before_restore(processes: &[(usize, String, Option<i64>)]) -> Result<(), String> {
    use std::thread;
    use std::time::Duration;
    use std::collections::HashSet;
    
    let mut killed_pids = Vec::new();
    
    // Collect all OPM-managed session IDs for filtering
    let opm_session_ids: HashSet<i64> = processes
        .iter()
        .filter_map(|(id, _, session_id)| {
            if session_id.is_none() {
                ::log::debug!("Process ID {} has no session ID stored", id);
            }
            *session_id
        })
        .collect();
    
    // SAFETY: If no valid session IDs are available, skip all killing to prevent
    // accidentally terminating unrelated processes. This is safer than trying to
    // match only by command pattern, which could match user processes.
    if opm_session_ids.is_empty() {
        ::log::debug!("No valid OPM session IDs found in dump - skipping process cleanup");
        return Ok(());
    }
    
    for (_id, script, _session_id) in processes {
        // Extract search pattern from command (same logic as daemon adoption)
        let pattern = extract_search_pattern_from_command(script);
        
        if pattern.is_empty() {
            continue;
        }
        
        // Find all processes matching this pattern
        let matching_pids = find_processes_by_command_pattern(&pattern);
        
        for pid in matching_pids {
            // Skip if we already killed this PID
            if killed_pids.contains(&pid) {
                continue;
            }
            
            // SAFETY CHECK: Only kill if process belongs to an OPM-managed session
            // This prevents killing user shells and unrelated processes
            // We check if this PID belongs to any OPM-managed session
            let should_kill = if let Some(proc_session_id) = unix::get_session_id(pid as i32) {
                if opm_session_ids.contains(&proc_session_id) {
                    ::log::info!(
                        "Process PID {} belongs to OPM session {} - will kill", 
                        pid, proc_session_id
                    );
                    true
                } else {
                    ::log::debug!(
                        "Process PID {} session {} is not OPM-managed - skipping", 
                        pid, proc_session_id
                    );
                    false
                }
            } else {
                // If we can't get session ID, be conservative and skip
                // Process may not exist, may be inaccessible, or may be a kernel thread
                ::log::debug!(
                    "Could not get session ID for PID {} - skipping to avoid killing unrelated processes", 
                    pid
                );
                false
            };
            
            if should_kill {
                ::log::info!("Killing OPM-managed process PID {} matching pattern '{}'", pid, pattern);
                
                // Force kill the process tree
                if let Err(e) = force_kill_process_tree(pid) {
                    ::log::warn!("Failed to kill process {}: {}", pid, e);
                } else {
                    killed_pids.push(pid);
                }
            }
        }
    }
    
    // Wait 500ms for OS to clean up resources
    if !killed_pids.is_empty() {
        ::log::info!("Killed {} OPM-managed processes, waiting {}ms for resource cleanup", killed_pids.len(), PROCESS_CLEANUP_WAIT_MS);
        thread::sleep(Duration::from_millis(PROCESS_CLEANUP_WAIT_MS));
    }
    
    Ok(())
}

/// Extract a search pattern from a command for process matching
/// Looks for distinctive parts like JAR files, script names, executables
///
/// # Examples
/// ```ignore
/// // JAR file extraction
/// extract_search_pattern_from_command("java -jar Stirling-PDF.jar") // => "Stirling-PDF.jar"
///
/// // Script file extraction
/// extract_search_pattern_from_command("python script.py") // => "script.py"
/// extract_search_pattern_from_command("node server.js") // => "server.js"
///
/// // Executable extraction
/// extract_search_pattern_from_command("caddy run") // => "caddy"
///
/// // Shell commands are skipped
/// extract_search_pattern_from_command("bash start.sh") // => "start.sh" (not "bash")
/// ```
fn extract_search_pattern_from_command(command: &str) -> String {
    // Look for patterns that uniquely identify the process
    // Priority: JAR files, then .py/.js/.sh files, then first word

    // Check for JAR files (e.g., "java -jar Stirling-PDF.jar")
    if let Some(jar_pos) = command.find(".jar") {
        // Find the start of the filename (after last space or slash)
        let before_jar = &command[..jar_pos];
        if let Some(start) = before_jar.rfind(|c: char| c == ' ' || c == '/') {
            let end = (jar_pos + 4).min(command.len());
            if start + 1 < end {
                let jar_name = &command[start + 1..end];
                return jar_name.trim().to_string();
            }
        }
    }

    // Check for common script extensions
    for ext in &[".py", ".js", ".sh", ".rb", ".pl", ".php", ".lua"] {
        if let Some(ext_pos) = command.find(ext) {
            let before_ext = &command[..ext_pos];
            if let Some(start) = before_ext.rfind(|c: char| c == ' ' || c == '/') {
                let end = (ext_pos + ext.len()).min(command.len());
                if start + 1 < end {
                    let script_name = &command[start + 1..end];
                    return script_name.trim().to_string();
                }
            }
        }
    }

    // Fall back to the first word if it looks like an executable
    if let Some(first_word) = command.split_whitespace().next() {
        if !first_word.is_empty() && !first_word.starts_with('-') {
            // Skip common shells
            if !matches!(first_word, "sh" | "bash" | "zsh" | "fish" | "dash") {
                return first_word.to_string();
            }
        }
    }

    // If all else fails, return empty (no matching will occur)
    String::new()
}

/// Find the children of the process
pub fn process_find_children(parent_pid: i64) -> Vec<i64> {
    let mut children = Vec::new();
    let mut to_check = vec![parent_pid];
    let mut checked = HashSet::new();

    #[cfg(target_os = "linux")]
    {
        while let Some(pid) = to_check.pop() {
            if checked.contains(&pid) {
                continue;
            }
            checked.insert(pid);

            let proc_path = format!("/proc/{}/task/{}/children", pid, pid);
            let Ok(contents) = std::fs::read_to_string(&proc_path) else {
                continue;
            };

            for child_pid_str in contents.split_whitespace() {
                if let Ok(child_pid) = child_pid_str.parse::<i64>() {
                    children.push(child_pid);
                    to_check.push(child_pid); // Check grandchildren
                }
            }
        }
    }

    #[cfg(not(target_os = "linux"))]
    {
        match unix::native_processes() {
            Ok(processes) => {
                // Build parent->children map in single pass
                let mut parent_map: HashMap<i64, Vec<i64>> = HashMap::new();

                processes.iter().for_each(|process| {
                    if let Ok(Some(ppid)) = process.ppid() {
                        parent_map
                            .entry(ppid as i64)
                            .or_insert_with(Vec::new)
                            .push(process.pid() as i64);
                    }
                });

                while let Some(pid) = to_check.pop() {
                    if let Some(direct_children) = parent_map.get(&pid) {
                        for &child in direct_children {
                            if !checked.contains(&child) {
                                children.push(child);
                                to_check.push(child);
                                checked.insert(child);
                            }
                        }
                    }
                }
            }
            Err(_) => {
                log::warn!("Native process enumeration failed for PID {}", parent_pid);
            }
        }
    }

    children
}
/// Check if any descendant (or the root PID) in the tracked set is alive
/// This includes the root pid, children, and grandchildren
pub fn is_any_descendant_alive(root_pid: i64, children: &[i64]) -> bool {
    // Check root PID first
    if is_pid_alive(root_pid) {
        return true;
    }

    // Check all tracked children
    for &child_pid in children {
        if is_pid_alive(child_pid) {
            return true;
        }
    }

    false
}

/// Enhanced process tree check using sysinfo for more robust detection
/// This checks if the process or any of its descendants are alive, using sysinfo
/// for better cross-platform process tree traversal.
pub fn is_process_or_children_alive_sysinfo(root_pid: i64, tracked_children: &[i64]) -> bool {
    use sysinfo::{ProcessRefreshKind, ProcessesToUpdate, System};

    // Quick check first - if root PID is alive, return immediately
    if is_pid_alive(root_pid) {
        return true;
    }

    // Quick check for tracked children
    for &child_pid in tracked_children {
        if is_pid_alive(child_pid) {
            return true;
        }
    }

    // Use sysinfo to discover any untracked descendants that might still be alive
    // This is useful when the shell wrapper exits but children are still running
    let mut system = System::new();
    system.refresh_processes_specifics(ProcessesToUpdate::All, true, ProcessRefreshKind::new());

    // Check for any children of the root PID that might not be tracked yet
    // This handles the case where bash -c spawns a child that we haven't discovered yet
    if root_pid > 0 {
        // Find all descendants of root_pid
        for (_pid, process) in system.processes() {
            if let Some(parent_pid) = process.parent() {
                // Convert parent_pid to i64 for comparison
                let parent_pid_i64 = parent_pid.as_u32() as i64;
                if parent_pid_i64 == root_pid {
                    // Found a direct child of root_pid that's alive
                    return true;
                }
                // Also check if parent is any of our tracked children
                if tracked_children.contains(&parent_pid_i64) {
                    return true;
                }
            }
        }
    }

    false
}

/// Check if any process in the same session is alive (using session ID)
/// This is more robust than tracking individual PIDs as it handles process forking
///
/// Note: This function refreshes all processes which is expensive, but:
/// 1. It's only called when the main PID is dead (rare case)
/// 2. Session-based checks are critical for correct process tracking
/// 3. The monitoring interval (default 1s) limits how often this runs
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn is_session_alive(session_id: i64) -> bool {
    use sysinfo::{ProcessRefreshKind, ProcessesToUpdate, System};

    let mut system = System::new();
    system.refresh_processes_specifics(ProcessesToUpdate::All, true, ProcessRefreshKind::new());

    // Check all processes to see if any have matching session ID
    for (sysinfo_pid, _process) in system.processes() {
        let pid = sysinfo_pid.as_u32() as i32;
        if let Some(proc_sid) = unix::get_session_id(pid) {
            if proc_sid == session_id {
                // Found a process with matching session ID
                if is_pid_alive(pid as i64) {
                    return true;
                }
            }
        }
    }

    false
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn is_session_alive(_session_id: i64) -> bool {
    false
}

/// Search for a process by command pattern
/// Returns the PID of the first matching process, or None if not found
///
/// Note: This function refreshes all processes which is expensive, but:
/// 1. It's only called when attempting process adoption (rare case, after crash)
/// 2. Process adoption is critical to prevent duplicate processes
/// 3. The cost is acceptable given it prevents severe issues like multiple service instances
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn find_process_by_command(command_pattern: &str) -> Option<i64> {
    use sysinfo::{ProcessRefreshKind, ProcessesToUpdate, System};

    let mut system = System::new();
    system.refresh_processes_specifics(ProcessesToUpdate::All, true, ProcessRefreshKind::new());

    // Search all processes for command line match
    for (sysinfo_pid, process) in system.processes() {
        let pid = sysinfo_pid.as_u32() as i32;

        // Try to get full command line first
        if let Some(cmdline) = unix::get_process_cmdline(pid) {
            if cmdline.contains(command_pattern) {
                log::info!(
                    "Found process by cmdline: PID {} matches pattern '{}'",
                    pid,
                    command_pattern
                );
                return Some(pid as i64);
            }
        }

        // Fallback to process name if cmdline not available
        let proc_name = process.name().to_string_lossy().to_string();
        if proc_name.contains(command_pattern) || command_pattern.contains(&proc_name) {
            log::info!(
                "Found process by name: PID {} ({}) matches pattern '{}'",
                pid,
                proc_name,
                command_pattern
            );
            return Some(pid as i64);
        }
    }

    None
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn find_process_by_command(_command_pattern: &str) -> Option<i64> {
    None
}

/// Check if PID info is missing/incomplete for crash detection purposes
/// Returns true if pid <= 0 and no tracked descendants
pub fn is_pid_info_missing(pid: i64, children: &[i64]) -> bool {
    pid <= 0 && children.is_empty()
}

/// Check if a process is actually alive by checking PID and shell_pid
/// Returns true if either the main PID or shell PID is alive
/// This matches the daemon logic which checks: is_pid_alive(pid) || shell_alive
pub fn is_process_actually_alive(pid: i64, shell_pid: Option<i64>) -> bool {
    let main_pid_alive = pid > 0 && is_pid_alive(pid);
    let shell_pid_alive = shell_pid.map_or(false, |spid| spid > 0 && is_pid_alive(spid));
    main_pid_alive || shell_pid_alive
}

/// Validate process state using sysinfo with PID reuse detection
/// Returns (is_valid, Option<start_time>) where:
/// - is_valid: true if process exists and matches expected parameters
/// - start_time: current process start time if found, for PID reuse detection
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn validate_process_with_sysinfo(
    pid: i64,
    expected_command_pattern: Option<&str>,
    expected_start_time: Option<u64>,
) -> (bool, Option<u64>) {
    use sysinfo::{Pid, ProcessRefreshKind, ProcessesToUpdate, System};

    if pid <= 0 {
        return (false, None);
    }

    let mut system = System::new();
    system.refresh_processes_specifics(ProcessesToUpdate::All, true, ProcessRefreshKind::new());

    let sysinfo_pid = Pid::from_u32(pid as u32);
    if let Some(process) = system.process(sysinfo_pid) {
        let current_start_time = process.start_time();

        // Check if PID has been reused by comparing start times
        if let Some(expected_time) = expected_start_time {
            if current_start_time != expected_time {
                log::warn!(
                    "PID {} has been reused (expected start time: {}, actual: {})",
                    pid,
                    expected_time,
                    current_start_time
                );
                return (false, Some(current_start_time));
            }
        }

        // Validate command pattern if provided
        if let Some(pattern) = expected_command_pattern {
            // Try to get full command line
            #[cfg(any(target_os = "linux", target_os = "macos"))]
            {
                if let Some(cmdline) = unix::get_process_cmdline(pid as i32) {
                    if !cmdline.contains(pattern) {
                        let proc_name = process.name().to_string_lossy().to_string();
                        if !proc_name.contains(pattern) && !pattern.contains(&proc_name) {
                            log::warn!(
                                "PID {} command mismatch (pattern: '{}', cmdline: '{}', name: '{}')",
                                pid, pattern, cmdline, proc_name
                            );
                            return (false, Some(current_start_time));
                        }
                    }
                }
            }
        }

        // Process is valid and matches expected parameters
        return (true, Some(current_start_time));
    }

    // Process not found
    (false, None)
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn validate_process_with_sysinfo(
    _pid: i64,
    _expected_command_pattern: Option<&str>,
    _expected_start_time: Option<u64>,
) -> (bool, Option<u64>) {
    (false, None)
}

/// Get comprehensive process metrics using sysinfo
/// Returns None if process not found or metrics unavailable
/// This is used to properly display "0b" memory and "offline" status
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn get_process_metrics_sysinfo(pid: i64) -> Option<(f64, u64, u64)> {
    use sysinfo::{Pid, ProcessRefreshKind, ProcessesToUpdate, System};

    if pid <= 0 {
        return None;
    }

    let mut system = System::new();
    system.refresh_processes_specifics(ProcessesToUpdate::All, true, ProcessRefreshKind::new());

    let sysinfo_pid = Pid::from_u32(pid as u32);
    system.process(sysinfo_pid).map(|process| {
        let cpu = process.cpu_usage() as f64;
        let memory = process.memory();
        let virtual_memory = process.virtual_memory();
        (cpu, memory, virtual_memory)
    })
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn get_process_metrics_sysinfo(_pid: i64) -> Option<(f64, u64, u64)> {
    None
}

/// Get OS-level uptime for a process using sysinfo
/// Returns uptime in seconds, or 0 if process not found
/// This is the authoritative source for uptime calculation - it uses the OS's actual
/// process start time, not application timestamps that can be stale after daemon restarts
#[cfg(any(target_os = "linux", target_os = "macos"))]
pub fn get_process_uptime_sysinfo(pid: i64) -> u64 {
    use sysinfo::{Pid, ProcessRefreshKind, ProcessesToUpdate, System};

    if pid <= 0 {
        return 0;
    }

    let mut system = System::new();
    let sysinfo_pid = Pid::from_u32(pid as u32);
    
    // Refresh only the specific process we need for efficiency
    system.refresh_processes_specifics(
        ProcessesToUpdate::Some(&[sysinfo_pid]),
        true,
        ProcessRefreshKind::new(),
    );

    if let Some(process) = system.process(sysinfo_pid) {
        // In sysinfo 0.30+, process.start_time() returns seconds since UNIX epoch
        // (not seconds since boot as in older versions)
        let process_start_time = process.start_time();
        
        let current_time = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map(|d| d.as_secs())
            .unwrap_or(0);
        
        // Calculate uptime: current_time - process_start_time
        if current_time > process_start_time {
            return current_time - process_start_time;
        }
    }

    0 // Process not found or invalid time calculation
}

#[cfg(not(any(target_os = "linux", target_os = "macos")))]
pub fn get_process_uptime_sysinfo(_pid: i64) -> u64 {
    0
}

#[cfg(target_os = "linux")]
pub fn find_alive_process_in_group(pid: i64) -> Option<i64> {
    unix::find_alive_process_in_group_for_pid(pid)
}

#[cfg(not(target_os = "linux"))]
pub fn find_alive_process_in_group(_pid: i64) -> Option<i64> {
    None
}

/// Result of running a process
#[derive(Debug, Clone)]
pub struct ProcessRunResult {
    pub pid: i64,
    pub shell_pid: Option<i64>,
    pub session_id: Option<i64>,
    pub start_time: Option<u64>,
}

/// Check if a command contains shell-specific features that require shell interpretation
/// Returns true if the command needs to be run through a shell (sh/bash)
/// Returns false if the command can be spawned directly for PM2-like behavior
///
/// Note: This is a heuristic check and may have false positives for complex edge cases
/// (e.g., backticks in quoted strings, & in URLs). For critical use cases where direct
/// execution must be guaranteed, prefer explicit command construction.
fn command_needs_shell(command: &str) -> bool {
    // Shell operators and features that require shell interpretation
    let shell_features = [
        "&&", "||", "|", // Logical operators and pipes
        ">", ">>", "<", // Redirection
        ";", // Command separator
        "`", "$(", // Command substitution
        "~",  // Home directory expansion
        "*", "?", "[", // Glob patterns
        "export ", "source ", "alias ", // Shell built-ins
    ];

    shell_features
        .iter()
        .any(|feature| command.contains(feature))
}

/// Parse command into program and arguments for direct execution
/// Returns None if parsing fails or command is complex
///
/// Note: This uses simple whitespace-based splitting and does NOT handle:
/// - Quoted arguments with spaces (e.g., program "arg with spaces")
/// - Escaped characters
/// - Complex shell quoting rules
/// For commands requiring such features, they will be detected by command_needs_shell()
/// and executed through a shell instead.
fn parse_direct_command(command: &str) -> Option<(String, Vec<String>)> {
    let trimmed = command.trim();
    if trimmed.is_empty() {
        return None;
    }

    // Simple whitespace-based splitting
    // This handles basic cases like "node server.js" or "python app.py"
    let mut parts: Vec<String> = trimmed.split_whitespace().map(|s| s.to_string()).collect();

    if parts.is_empty() {
        return None;
    }

    let program = parts.remove(0);
    Some((program, parts))
}

/// Run the process
pub fn process_run(metadata: ProcessMetadata) -> Result<ProcessRunResult, String> {
    use std::fs::{self, OpenOptions};
    use std::process::{Command, Stdio};

    let log_base = format!("{}/{}", metadata.log_path, metadata.name.replace(' ', "_"));
    let stdout_path = format!("{}-out.log", log_base);
    let stderr_path = format!("{}-error.log", log_base);

    // Create parent directories for log files if they don't exist
    // This handles cases where process name contains slashes (e.g., "server/server.js")
    // Both stdout and stderr use the same log_base, so we only need to create directories once
    if let Some(parent) = std::path::Path::new(&log_base).parent() {
        fs::create_dir_all(parent).map_err(|err| {
            format!(
                "Failed to create log directory '{}': {}. \
                Check that you have write permissions.",
                parent.display(),
                err
            )
        })?;
    }

    // Create log files
    let stdout_file = OpenOptions::new()
        .create(true)
        .append(true)
        .open(&stdout_path)
        .map_err(|err| {
            format!(
                "Failed to open stdout log file '{}': {}. \
                Check that the directory exists and you have write permissions.",
                stdout_path, err
            )
        })?;

    let stderr_file = OpenOptions::new()
        .create(true)
        .append(true)
        .open(&stderr_path)
        .map_err(|err| {
            format!(
                "Failed to open stderr log file '{}': {}. \
                Check that the directory exists and you have write permissions.",
                stderr_path, err
            )
        })?;

    // PM2-like execution strategy: spawn directly if possible, otherwise use shell
    // This eliminates the intermediate shell PID problem for simple commands
    let use_direct_spawn = !command_needs_shell(&metadata.command);

    let mut cmd = if use_direct_spawn {
        // Try to parse and spawn directly without shell wrapper
        if let Some((program, args)) = parse_direct_command(&metadata.command) {
            log::debug!("Spawning '{}' directly without shell wrapper", program);
            let mut command = Command::new(&program);
            command.args(&args);
            command
        } else {
            // Parsing failed, fall back to shell
            log::debug!(
                "Direct spawn parsing failed, using shell: {}",
                metadata.shell
            );
            let mut command = Command::new(&metadata.shell);
            command.args(&metadata.args).arg(&metadata.command);
            command
        }
    } else {
        // Command needs shell features (pipes, redirects, etc.)
        // Use the configured shell from config.toml (sh or bash)
        log::debug!(
            "Using configured shell '{}' for command with shell operators",
            metadata.shell
        );
        let mut command = Command::new(&metadata.shell);
        command.args(&metadata.args).arg(&metadata.command);
        command
    };

    cmd.envs(metadata.env.iter().map(|env_var| {
        let parts: Vec<&str> = env_var.splitn(2, '=').collect();
        if parts.len() == 2 {
            (parts[0], parts[1])
        } else {
            (env_var.as_str(), "")
        }
    }))
    .stdout(Stdio::from(stdout_file))
    .stderr(Stdio::from(stderr_file))
    .stdin(Stdio::null());

    // Create a new session for better process tree management
    // This uses setsid() to create a new session where this process is the session leader
    // This ensures all children inherit the same session ID for robust tracking
    #[cfg(unix)]
    {
        use std::os::unix::process::CommandExt;
        unsafe {
            cmd.pre_exec(|| {
                // Create new session - this process becomes session leader
                libc::setsid();
                Ok(())
            });
        }
    }

    let child = cmd.spawn().map_err(|err| {
        // Provide more helpful error messages based on error kind
        match err.kind() {
            std::io::ErrorKind::NotFound => {
                if use_direct_spawn {
                    if let Some((program, _)) = parse_direct_command(&metadata.command) {
                        format!(
                            "Failed to spawn process: Command '{}' not found. \
                            Please ensure '{}' is installed and in your PATH. \
                            Error: {:?}",
                            program, program, err
                        )
                    } else {
                        format!(
                            "Failed to spawn process: Command '{}' not found. Error: {:?}",
                            metadata.command, err
                        )
                    }
                } else {
                    format!(
                        "Failed to spawn process: Shell '{}' not found. \
                        Please ensure '{}' is installed and in your PATH. \
                        Error: {:?}",
                        metadata.shell, metadata.shell, err
                    )
                }
            }
            std::io::ErrorKind::PermissionDenied => {
                if use_direct_spawn {
                    format!(
                        "Failed to spawn process: Permission denied for '{}'. \
                        Check that the program has execute permissions. \
                        Error: {:?}",
                        metadata.command, err
                    )
                } else {
                    format!(
                        "Failed to spawn process: Permission denied for '{}'. \
                        Check that the shell has execute permissions. \
                        Error: {:?}",
                        metadata.shell, err
                    )
                }
            }
            _ => {
                if use_direct_spawn {
                    format!(
                        "Failed to spawn process directly: {:?}. \
                        Command attempted: '{}'",
                        err, metadata.command
                    )
                } else {
                    format!(
                        "Failed to spawn process with shell '{}': {:?}. \
                        Command attempted: {} {} '{}'",
                        metadata.shell,
                        err,
                        metadata.shell,
                        metadata.args.join(" "),
                        metadata.command
                    )
                }
            }
        }
    })?;

    // PID of the process spawned by Command::spawn()
    // For direct spawns: this is the application PID
    // For shell-wrapped spawns: this is the shell wrapper PID
    let spawned_pid = child.id() as i64;

    // Determine the actual application PID
    // For shell-wrapped processes, wait briefly to allow OS to register process tree
    // This ensures sysinfo can discover child processes during PID stability checks
    // For direct spawns, no wait needed as there's no shell wrapper to track
    let actual_pid = if use_direct_spawn {
        // For direct spawns, child.id() is already the actual application PID
        // No need to search for children since there's no shell wrapper
        spawned_pid
    } else {
        // For shell-wrapped spawns, wait for process tree to stabilize
        std::thread::sleep(std::time::Duration::from_millis(200));
        // Find the actual application PID from the shell wrapper's children
        unix::get_actual_child_pid(spawned_pid)
    };

    // Store child handle in global state to prevent it from being dropped and becoming a zombie
    // This is critical for PM2-like daemon functionality
    // Use spawned_pid (not actual_pid) because this is the direct child we spawned
    PROCESS_HANDLES.insert(spawned_pid, Arc::new(Mutex::new(child)));

    // For direct spawns, spawned_pid and actual_pid are the same (no shell wrapper)
    // For shell-wrapped commands, they differ and we need to track both
    let shell_pid_opt = if use_direct_spawn {
        None // No shell wrapper for direct spawns
    } else {
        (spawned_pid != actual_pid).then_some(spawned_pid)
    };

    // Get session ID of the spawned process for session-based tracking
    #[cfg(any(target_os = "linux", target_os = "macos"))]
    let session_id = unix::get_session_id(actual_pid as i32);

    #[cfg(not(any(target_os = "linux", target_os = "macos")))]
    let session_id: Option<i64> = None;

    // Capture process start time for PID reuse detection
    // validate_process_with_sysinfo will refresh process list from OS
    let start_time = validate_process_with_sysinfo(actual_pid, None, None).1;

    Ok(ProcessRunResult {
        pid: actual_pid,
        shell_pid: shell_pid_opt,
        session_id,
        start_time,
    })
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;
    use std::thread;
    use std::time::Duration;

    fn setup_test_runner() -> Runner {
        Runner {
            id: id::Id::new(1),
            list: BTreeMap::new(),
            remote: None,
        }
    }

    // Use a PID value that's unlikely to exist in the test environment
    const UNLIKELY_PID: i64 = i32::MAX as i64 - 1000;

    #[test]
    fn test_environment_variables() {
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello world'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Test setting environment variables
        let mut env = BTreeMap::new();
        env.insert("TEST_VAR".to_string(), "test_value".to_string());
        env.insert("ANOTHER_VAR".to_string(), "another_value".to_string());

        runner.set_env(id, env);

        let process_env = &runner.info(id).unwrap().env;
        assert_eq!(process_env.get("TEST_VAR"), Some(&"test_value".to_string()));
        assert_eq!(
            process_env.get("ANOTHER_VAR"),
            Some(&"another_value".to_string())
        );

        // Test clearing environment variables
        runner.clear_env(id);
        assert!(runner.info(id).unwrap().env.is_empty());
    }

    #[test]
    fn test_children_processes() {
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello world'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Test setting children
        let children = vec![12346, 12347, 12348];
        runner.set_children(id, children.clone());

        assert_eq!(runner.info(id).unwrap().children, children);
    }

    #[test]
    fn test_cpu_usage_measurement() {
        // Test with current process (should return valid percentage)
        let current_pid = std::process::id() as i64;
        let cpu_usage = get_process_cpu_usage_percentage(current_pid);

        // CPU usage should be between 0 and 100% (single process can't use more than 100% of available CPU)
        assert!(cpu_usage >= 0.0);
        assert!(cpu_usage <= 100.0);

        println!("CPU usage: {}", cpu_usage);

        // Test with invalid PID (should return 0.0)
        let invalid_pid = 999999;
        let cpu_usage = get_process_cpu_usage_percentage(invalid_pid);
        assert_eq!(cpu_usage, 0.0);
    }

    // Integration test for actual process operations
    #[test]
    #[ignore = "it requires actual process execution"]
    fn test_real_process_execution() {
        let metadata = ProcessMetadata {
            name: "test_echo".to_string(),
            shell: "/bin/sh".to_string(),
            command: "echo 'Hello from test'".to_string(),
            log_path: "/tmp".to_string(),
            args: vec!["-c".to_string()],
            env: vec!["TEST_ENV=test_value".to_string()],
        };

        match process_run(metadata) {
            Ok(result) => {
                assert!(result.pid > 0);

                // Wait a bit for process to complete
                thread::sleep(Duration::from_millis(100));

                // Try to stop it (might already be finished)
                let _ = process_stop(result.pid);
            }
            Err(e) => {
                panic!("Failed to run test process: {}", e);
            }
        }
    }

    #[test]
    fn test_reset_counters() {
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello world'".to_string(),
            restarts: 5, // Set to non-zero value
            running: true,
            crash: Crash {
                crashed: true, // Set to crashed
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial values
        assert_eq!(runner.info(id).unwrap().restarts, 5);
        assert_eq!(runner.info(id).unwrap().crash.crashed, true);

        // Reset counters
        runner.reset_counters(id);

        // Verify counters are reset
        assert_eq!(runner.info(id).unwrap().restarts, 0);
        assert_eq!(runner.info(id).unwrap().crash.crashed, false);
    }

    #[test]
    fn test_cpu_usage_with_children_performance() {
        use std::time::Instant;

        // Test that measuring CPU with children is reasonably fast
        // even with multiple children, since we use fast measurements for children
        let current_pid = std::process::id() as i64;

        // Simulate finding children (even if empty, the function should be fast)
        let start = Instant::now();
        let _cpu_with_children = get_process_cpu_usage_with_children_fast(current_pid);
        let duration = start.elapsed();

        // Fast version should complete very quickly (< 50ms even with multiple children)
        // since it doesn't use delay-based sampling
        assert!(
            duration.as_millis() < 50,
            "Fast CPU measurement with children took too long: {:?}",
            duration
        );

        // Test that the timed version with a pre-created process is also reasonably fast
        // It should only have one delay (for parent), not cumulative delays per child
        if let Ok(process) = unix::NativeProcess::new(current_pid as u32) {
            let start = Instant::now();
            let _cpu_with_children =
                get_process_cpu_usage_with_children_from_process(&process, current_pid);
            let duration = start.elapsed();

            // This should complete quickly since the parent measurement was already taken
            // and children use fast measurements (no additional delays)
            assert!(
                duration.as_millis() < 50,
                "CPU measurement with pre-created process took too long: {:?}",
                duration
            );
        }
    }

    #[test]
    fn test_cpu_usage_consistency() {
        // Test that CPU measurements are consistent and within expected ranges
        let current_pid = std::process::id() as i64;

        // Get CPU usage with different methods
        let fast_cpu = get_process_cpu_usage_percentage_fast(current_pid);
        let fast_cpu_with_children = get_process_cpu_usage_with_children_fast(current_pid);

        // Single process should be 0-100%
        assert!(fast_cpu >= 0.0);
        assert!(fast_cpu <= 100.0);

        // Process with children can exceed 100% if multiple processes run in parallel
        assert!(fast_cpu_with_children >= 0.0);

        // CPU with children should be >= CPU of parent alone (assuming no negative children)
        assert!(
            fast_cpu_with_children >= fast_cpu - 0.1,
            "CPU with children ({}) should be >= parent CPU ({})",
            fast_cpu_with_children,
            fast_cpu
        );
    }

    #[test]
    fn test_error_handling_invalid_shell() {
        // Test that process_run returns an error for invalid shell
        // Use a command with shell operators (|) to force shell usage
        let metadata = ProcessMetadata {
            name: "test_process".to_string(),
            shell: "/nonexistent/shell/that/does/not/exist".to_string(),
            command: "echo test | cat".to_string(), // Pipe forces shell usage
            log_path: "/tmp".to_string(),
            args: vec!["-c".to_string()],
            env: vec![],
        };

        let result = process_run(metadata);
        assert!(result.is_err(), "Expected error for nonexistent shell");

        let err_msg = result.unwrap_err();
        // Check that the error message mentions the shell and that it wasn't found
        assert!(
            err_msg.contains("/nonexistent/shell/that/does/not/exist")
                && (err_msg.contains("not found")
                    || err_msg.contains("Shell")
                    || err_msg.contains("Failed to spawn")),
            "Error message should indicate shell not found, got: {}",
            err_msg
        );
    }

    #[test]
    fn test_error_handling_invalid_log_path() {
        // Test that process_run returns an error for invalid log path
        let metadata = ProcessMetadata {
            name: "test_process".to_string(),
            shell: "/bin/sh".to_string(),
            command: "echo test".to_string(),
            log_path: "/nonexistent/directory/that/does/not/exist".to_string(),
            args: vec!["-c".to_string()],
            env: vec![],
        };

        let result = process_run(metadata);
        assert!(result.is_err(), "Expected error for nonexistent log path");

        let err_msg = result.unwrap_err();
        assert!(
            (err_msg.contains("Failed to open") && err_msg.contains("log file"))
                || (err_msg.contains("Failed to create log directory")),
            "Error message should indicate log file or directory error, got: {}",
            err_msg
        );
    }

    #[test]
    fn test_error_handling_graceful_failure() {
        // Test that runner doesn't panic when restart fails
        // This test verifies the structure is set up correctly for error handling
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: false, // Start with not running
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify the process exists
        assert!(runner.exists(id), "Process should exist in runner");

        // Verify process state
        let process = runner.info(id).unwrap();
        assert_eq!(
            process.running, false,
            "Process should start as not running"
        );
        assert_eq!(
            process.crash.crashed, false,
            "Process should start as not crashed"
        );
    }

    #[test]
    fn test_status_detection_with_dead_pid() {
        // Test that processes marked as running but with dead PIDs show as crashed
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: true, // Marked as running
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Fetch the process list and check status
        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");

        // The process is marked as running but the PID doesn't exist.
        // It should show as "starting" during the grace period instead of "crashed".
        assert_eq!(
            processes[0].status, "starting",
            "Process with dead PID should show as starting during grace period"
        );
    }

    #[test]
    fn test_uptime_not_counted_for_crashed_process() {
        // Test that crashed processes show "0s" uptime, not accumulated time
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process with a start time in the past
        let past_time = Utc::now() - chrono::Duration::seconds(300); // 5 minutes ago

        let process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_crashed_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: true, // Marked as running but PID doesn't exist
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: past_time, // Started 5 minutes ago
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Fetch the process list
        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");

        // The process is marked as running but the PID doesn't exist - it's crashed after grace period
        assert_eq!(
            processes[0].status, "crashed",
            "Process with dead PID should show as crashed after grace period"
        );

        // Uptime should be "0s", not "5m" or similar
        assert_eq!(
            processes[0].uptime, "0s",
            "Crashed process should show 0s uptime, not accumulated time"
        );
    }

    #[test]
    fn test_dead_pid_after_grace_period_shows_crashed() {
        // Test that processes marked as running but with dead PIDs show as crashed after grace period
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now() - chrono::Duration::seconds(20),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");
        assert_eq!(
            processes[0].status, "crashed",
            "Process with dead PID should show as crashed after grace period"
        );
    }

    #[test]
    fn test_uptime_not_counted_for_stopped_process() {
        // Test that stopped processes also show "0s" uptime
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process with a start time in the past
        let past_time = Utc::now() - chrono::Duration::seconds(600); // 10 minutes ago

        let process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_stopped_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: false, // Explicitly stopped
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: past_time, // Started 10 minutes ago
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Fetch the process list
        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");

        // The process is stopped
        assert_eq!(
            processes[0].status, "stopped",
            "Process should show as stopped"
        );

        // Uptime should be "0s", not "10m" or similar
        assert_eq!(
            processes[0].uptime, "0s",
            "Stopped process should show 0s uptime, not accumulated time"
        );
    }

    #[test]
    fn test_set_crashed_keeps_running_flag() {
        // Test that set_crashed sets crashed=true but KEEPS running=true
        // This is critical for daemon auto-restart to work properly
        // The daemon only attempts restarts for processes where running=true
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state
        let process = runner.info(id).unwrap();
        assert_eq!(process.running, true, "Process should start as running");
        assert_eq!(
            process.crash.crashed, false,
            "Process should start as not crashed"
        );

        // Call set_crashed
        runner.set_crashed(id);

        // Verify that crashed is set but running remains true for daemon to attempt restart
        let process = runner.info(id).unwrap();
        assert_eq!(
            process.crash.crashed, true,
            "Process should be marked as crashed"
        );
        assert_eq!(
            process.running, true,
            "Process should remain marked as running so daemon will restart it"
        );
    }

    #[test]
    fn test_crash_counter_boundary_conditions() {
        // Test that crash.value behaves correctly at the boundaries
        // This validates the fix for allowing exactly max_restarts attempts
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Test with crash.value = 9 (should be allowed to restart if max=10)
        let mut process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process_9_crashes".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 9,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process.clone());

        // SEMANTIC CHANGE: max_restarts now represents the maximum counter value (not attempts)
        // With max_restarts=10, crash.value in range 1-9 allows restart (< 10)
        // Counter reaches 10 and stops there (displays the limit value)
        // Previous behavior: counter would go to 11 before stopping
        let max_restarts = 10;
        assert!(
            process.restarts < max_restarts,
            "crash.value=9 should be < max_restarts=10, allowing restart"
        );

        // Test with crash.value = 10 (should NOT be allowed to restart if max=10 with >= check)
        process.restarts = 10;
        runner.list.insert(id, process.clone());

        // With max_restarts=10, crash.value=10 should NOT allow restart (10 >= 10)
        // This ensures counter stops at 10 when limit is 10, displaying the limit value
        assert!(
            process.restarts >= max_restarts,
            "crash.value=10 should be >= max_restarts=10, preventing restart (counter displays limit and stops)"
        );

        // Test with crash.value = 11 (should also NOT be allowed to restart if max=10)
        process.restarts = 11;
        runner.list.insert(id, process.clone());

        // With max_restarts=10, crash.value=11 should NOT allow restart (11 >= 10)
        assert!(
            process.restarts >= max_restarts,
            "crash.value=11 should be >= max_restarts=10, preventing restart"
        );
    }

    #[test]
    fn test_crash_counter_display_beyond_limit() {
        // Test that crash counter displays actual value even when it exceeds max_restarts
        // This validates the fix for showing true crash count beyond the limit
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process with crash.value = 15 (exceeds typical limit of 10)
        let process = Process {
            id,
            pid: 0, // Not running
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process_15_crashes".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 15, // Set to 15 to test display beyond limit
            running: false,
            crash: Crash { crashed: true },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process.clone());

        // Test build_process_item - should display actual restarts counter value (15) not capped at max_restarts (10)
        let process_item = runner.build_process_item(id, &process);
        assert_eq!(
            process_item.restarts, 15,
            "ProcessItem should display actual restart counter value (15) even when it exceeds max_restarts (10)"
        );
    }

    #[test]
    fn test_restart_counter_not_incremented_on_start_command() {
        // Test that 'opm start' command (dead=false, increment_counter=false) does NOT increment
        // This ensures the counter doesn't increase when user starts an existing process
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 5, // Start with 5 restarts
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state
        assert_eq!(
            runner.info(id).unwrap().restarts,
            5,
            "Should start with 5 restarts"
        );

        // Start command (dead=false, increment_counter=false) should NOT increment
        // So the counter should remain at 5
        assert_eq!(
            runner.info(id).unwrap().restarts,
            5,
            "Start command should NOT increment counter"
        );
    }

    #[test]
    fn test_restart_counter_increments_on_restart_command() {
        // Test that 'opm restart' command (dead=false, increment_counter=true) DOES increment
        // This ensures the counter tracks manual restart commands
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 5, // Start with 5 restarts
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state
        assert_eq!(
            runner.info(id).unwrap().restarts,
            5,
            "Should start with 5 restarts"
        );

        // Simulate restart command (increment_counter=true)
        let proc = runner.process(id);
        proc.restarts += 1;

        // Verify the counter incremented
        assert_eq!(
            runner.info(id).unwrap().restarts,
            6,
            "Restart command should increment counter from 5 to 6"
        );
    }

    #[test]
    fn test_restart_counter_increments_on_crash_restart() {
        // Test that crash restarts (dead=true) DO increment the restart counter
        // This ensures automatic daemon restarts are tracked
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: UNLIKELY_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_crashed_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 2, // Start with 2 restarts already
            running: false,
            crash: Crash { crashed: true },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state
        assert_eq!(
            runner.info(id).unwrap().restarts,
            2,
            "Should start with 2 restarts"
        );

        // Simulate what the daemon does when it detects a crash and restarts (dead=true)
        let proc = runner.process(id);
        proc.restarts += 1; // This is conditional on dead=true in the actual code

        // Verify the counter incremented
        assert_eq!(
            runner.info(id).unwrap().restarts,
            3,
            "Crash restart should increment counter from 2 to 3"
        );

        // The crash.value would be managed separately by the daemon
        // and is reset to 0 on successful restart (not tested here)
    }

    #[test]
    fn test_reload_counter_increments_on_reload_command() {
        // Test that 'opm reload' command (dead=false, increment_counter=true) DOES increment
        // Reload is similar to restart but with zero-downtime (starts new before stopping old)
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 12345,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 5, // Start with 5 restarts
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state
        assert_eq!(
            runner.info(id).unwrap().restarts,
            5,
            "Should start with 5 restarts"
        );

        // Simulate reload command (increment_counter=true)
        let proc = runner.process(id);
        proc.restarts += 1;

        // Verify the counter incremented
        assert_eq!(
            runner.info(id).unwrap().restarts,
            6,
            "Reload command should increment counter from 5 to 6"
        );
    }

    #[test]
    fn test_restore_failed_process_keeps_running_for_daemon() {
        // Test that when restore fails, the process is marked as:
        // - crashed=true (so it shows as crashed)
        // - running=true (so daemon will attempt to restart it)
        // This is the key fix for the restore issue
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: UNLIKELY_PID, // Invalid PID - restore will fail
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_restore_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 0,
            running: true, // Was running before restore
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Simulate what restore does when it detects a failed process
        // (just the marking part, not the actual restart attempt or save)
        runner.set_crashed(id);

        // Verify the process state after "failed restore"
        let process = runner.info(id).unwrap();
        assert_eq!(
            process.crash.crashed, true,
            "Failed restore should mark process as crashed"
        );
        assert_eq!(
            process.running, true,
            "Failed restore should keep running=true so daemon will attempt restart"
        );

        // Verify that crash counter is NOT incremented by restore
        // (the daemon will increment it when it detects the crash)
        assert_eq!(
            process.restarts, 0,
            "Restore should not increment crash counter - daemon will do it"
        );
    }

    #[test]
    fn test_restored_process_shows_as_online_not_crashed() {
        // Test that restored processes (PID=0, running=true) show as "starting" not "crashed"
        // This prevents false "crashed" status after system restore/reboot
        // and accurately reflects that the process is waiting to be started by the daemon
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 0, // Restored process has PID=0 before daemon starts it
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_restored_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: true, // Marked as running by restore command
            crash: Crash {
                crashed: false, // Reset by restore command
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Fetch the process list and check status
        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");

        // Restored process should show as "starting" not "crashed"
        // This accurately reflects that the process is waiting to be started by daemon
        // Previously this showed as "online" which was misleading since PID=0 means not running
        assert_eq!(
            processes[0].status, "starting",
            "Restored process with PID=0 should show as starting, not crashed or online"
        );
    }

    #[test]
    fn test_is_pid_alive_detects_zombies() {
        // Test that is_pid_alive returns false for zombie processes
        // We can't easily create a zombie in a test, but we can verify
        // that the function exists and works correctly for non-zombie processes

        // Current process should be alive and not a zombie
        let current_pid = std::process::id() as i64;
        assert!(
            is_pid_alive(current_pid),
            "Current process should be detected as alive"
        );

        // Invalid PID should not be alive
        assert!(
            !is_pid_alive(UNLIKELY_PID),
            "Invalid PID should not be detected as alive"
        );

        // PID 0 should not be alive (special case)
        assert!(!is_pid_alive(0), "PID 0 should not be detected as alive");

        // Negative PID should not be alive
        assert!(
            !is_pid_alive(-1),
            "Negative PID should not be detected as alive"
        );
    }

    #[test]
    fn test_wait_for_process_termination_with_invalid_pids() {
        use std::time::Instant;

        // Test that wait_for_process_termination returns immediately for PID 0
        // Previously, this would cause a 5-second delay because libc::kill(0, 0)
        // checks the entire process group instead of a specific process
        let start = Instant::now();
        let result = wait_for_process_termination(0);
        let duration = start.elapsed();

        assert!(
            result,
            "wait_for_process_termination should return true for PID 0"
        );
        assert!(
            duration.as_millis() < 100,
            "wait_for_process_termination(0) should return immediately, took {:?}",
            duration
        );

        // Test with negative PID
        let start = Instant::now();
        let result = wait_for_process_termination(-1);
        let duration = start.elapsed();

        assert!(
            result,
            "wait_for_process_termination should return true for negative PID"
        );
        assert!(
            duration.as_millis() < 100,
            "wait_for_process_termination(-1) should return immediately, took {:?}",
            duration
        );

        // Test with unlikely PID (should also return quickly since process doesn't exist)
        let start = Instant::now();
        let result = wait_for_process_termination(UNLIKELY_PID);
        let duration = start.elapsed();

        assert!(
            result,
            "wait_for_process_termination should return true for non-existent PID"
        );
        assert!(
            duration.as_millis() < 200,
            "wait_for_process_termination(non-existent) should return quickly, took {:?}",
            duration
        );
    }

    #[test]
    #[ignore = "Requires config file which doesn't exist in test environment"]
    fn test_restart_failure_increments_crash_counter() {
        // Test that when restart() fails repeatedly due to bad config (e.g., bad working directory),
        // the crash counter is NOT double-incremented (bug fix for counter stopping at 8).
        //
        // OLD BEHAVIOR (BUG): Daemon increments + restart failure increments = counter jumps by 2
        // NEW BEHAVIOR (FIX): Only daemon increments, restart failure does NOT increment for dead=true
        //
        // This ensures counter reaches limit of 10 correctly instead of stopping at 8.

        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process with a non-existent working directory
        // This will cause restart() to fail at the set_current_dir step
        let process = Process {
            id,
            pid: 0, // Dead process
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_restart_failure".to_string(),
            path: PathBuf::from("/nonexistent/directory/that/does/not/exist"),
            script: "echo 'test'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash {
                crashed: true, // Already marked as crashed, so restart will be attempted
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Simulate daemon calling restart with dead=true (auto-restart after crash)
        // This should fail due to invalid working directory
        // With our fix: counter should NOT increment again (daemon already incremented to 1)
        runner.restart(id, true, true);

        // Verify that crash.value was NOT double-incremented
        let process = runner.info(id).unwrap();
        assert_eq!(
            process.restarts, 1,
            "After daemon restart failure, counter should stay at 1 (no double increment)"
        );
        assert_eq!(
            process.crash.crashed, true,
            "Restart failure should keep crashed flag set"
        );
        assert_eq!(
            process.running, true,
            "Restart failure should keep running=true so daemon will retry (not yet at limit)"
        );

        // Simulate daemon detecting more crashes and restart failures (crashes 2-9)
        // Each iteration: daemon increments, then restart fails (no additional increment)
        // Loop covers crash values 2 through 9; crash 10 is tested separately below
        let max_restarts = 10;
        for expected_crash_value in 2..max_restarts {
            // Daemon detects another crash and increments
            {
                let process = runner.process(id);
                process.restarts += 1;
            }

            // Daemon tries to restart (will fail)
            runner.restart(id, true, true);

            let process = runner.info(id).unwrap();
            assert_eq!(
                process.restarts, expected_crash_value,
                "After daemon crash detection #{}, counter should be {} (single increment)",
                expected_crash_value, expected_crash_value
            );
            assert_eq!(
                process.running, true,
                "Process should still be running (within restart limit)"
            );
        }

        // At 9, we're one away from the limit - next daemon increment to 10 should stop it
        {
            let process = runner.process(id);
            process.restarts += 1; // 10
        }
        runner.restart(id, true, true);

        let process = runner.info(id).unwrap();
        assert_eq!(
            process.restarts, 10,
            "Crash counter should be 10 when reaching limit"
        );
        assert_eq!(
            process.running, false,
            "Process should be stopped after reaching max restart limit"
        );
        assert_eq!(
            process.crash.crashed, true,
            "Process should still be marked as crashed"
        );
    }

    #[test]
    fn test_crash_counter_increments_after_manual_restart() {
        // Test for the bug: "The crash counter stops at 9th crash and doesn't increment after restart"
        // This test verifies that the crash counter properly increments even after manual restarts

        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process that has crashed 9 times (one away from the limit of 10)
        let process = Process {
            id,
            pid: 0, // Dead process
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process_at_limit".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 9,
            running: false, // Stopped after reaching limit
            crash: Crash {
                crashed: true, // Marked as crashed
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state: 9 crashes, crashed=true
        assert_eq!(runner.info(id).unwrap().restarts, 9);
        assert_eq!(runner.info(id).unwrap().crash.crashed, true);

        // Now simulate a manual restart by user (this should succeed in starting the process)
        // In a real scenario, this would start the process, but we'll simulate it by
        // manually setting the state as if restart succeeded
        {
            let process = runner.process(id);
            process.pid = 12345; // Simulate successful start
            process.running = true;
            // CRITICAL: Our fix ensures crashed=false is only set AFTER successful restart
            // Before the fix, crashed would be false here, breaking future crash detection
            // After the fix, we need to manually clear it to simulate successful restart
            process.crash.crashed = false; // This simulates the fix: cleared AFTER success
        }

        // Verify process is running and crashed flag was cleared
        assert_eq!(
            runner.info(id).unwrap().crash.crashed,
            false,
            "crashed flag should be cleared after successful restart"
        );
        assert_eq!(runner.info(id).unwrap().running, true);

        // Now simulate the process crashing again (pid dies)
        {
            let process = runner.process(id);
            process.pid = 0; // Process died
        }

        // At this point, the daemon would detect the crash and increment the counter
        // Simulate what daemon does in daemon/mod.rs around line 177-185
        {
            let process_info = runner.info(id).unwrap();
            if !process_info.crash.crashed {
                let process = runner.process(id);
                process.restarts += 1;
                process.crash.crashed = true;
            }
        }

        // Verify the counter incremented from 9 to 10
        assert_eq!(
            runner.info(id).unwrap().restarts,
            10,
            "Crash counter should increment from 9 to 10 after process crashes again"
        );
        assert_eq!(
            runner.info(id).unwrap().crash.crashed,
            true,
            "Process should be marked as crashed"
        );
    }

    #[test]
    fn test_auto_restart_10_times_then_manual_restart_increments() {
        // Comprehensive test for user's verification request:
        // 1. Verify auto-restart happens while counter < limit (max_restarts=10)
        // 2. Verify counter stops at 10 when limit is reached
        // 3. Verify after manual restart, crash counter continues to increment

        let mut runner = setup_test_runner();
        let id = runner.id.next();
        const MAX_RESTARTS: u64 = 10;
        const INITIAL_PID: i64 = 12345;
        const MANUAL_RESTART_PID: i64 = 99999;

        // Start with a healthy process
        let process = Process {
            id,
            pid: INITIAL_PID,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_auto_restart_limit".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Simulate crashes 1 through 10 (inclusive)
        // - Crashes 1-9: should auto-restart (counter < MAX_RESTARTS)
        // - Crash 10: should stop (counter >= MAX_RESTARTS)
        for expected_crash_count in 1..=MAX_RESTARTS {
            // Simulate process crash
            {
                let process = runner.process(id);
                process.pid = 0; // Process died
            }

            // Daemon detects crash and increments counter
            {
                let process_info = runner.info(id).unwrap();
                if !process_info.crash.crashed {
                    let process = runner.process(id);
                    process.restarts += 1;
                    process.crash.crashed = true;
                }
            }

            // Verify crash was counted
            assert_eq!(
                runner.info(id).unwrap().restarts,
                expected_crash_count,
                "After crash #{}, counter should be {}",
                expected_crash_count,
                expected_crash_count
            );

            // Check if we should continue auto-restarting (crash_count < MAX_RESTARTS)
            let should_auto_restart = expected_crash_count < MAX_RESTARTS;

            if should_auto_restart {
                // Daemon attempts auto-restart (simulating successful restart)
                {
                    let process = runner.process(id);
                    // Use unique PID for each restart
                    process.pid = INITIAL_PID + (expected_crash_count as i64 * 100);
                    process.running = true;
                    // With our fix: crashed flag cleared AFTER successful restart
                    process.crash.crashed = false;
                    process.last_action_at = Utc::now();
                }

                assert_eq!(
                    runner.info(id).unwrap().running,
                    true,
                    "After crash #{}, process should auto-restart (within limit of {})",
                    expected_crash_count,
                    MAX_RESTARTS
                );
            } else {
                // At crash 10, daemon should stop auto-restarting
                {
                    let process = runner.process(id);
                    process.running = false;
                }
                assert_eq!(
                    runner.info(id).unwrap().running,
                    false,
                    "At crash #{}, daemon should stop auto-restart (reached limit of {})",
                    expected_crash_count,
                    MAX_RESTARTS
                );
            }
        }

        // Verify we're at 10 crashes and process is stopped
        assert_eq!(
            runner.info(id).unwrap().restarts,
            10,
            "Counter should be at 10 after reaching the limit"
        );
        assert_eq!(
            runner.info(id).unwrap().running,
            false,
            "Process should be stopped when counter reaches the limit (10)"
        );

        // NOW TEST MANUAL RESTART AFTER LIMIT
        // User manually restarts the process
        {
            let process = runner.process(id);
            process.pid = MANUAL_RESTART_PID; // Manual restart succeeds
            process.running = true;
            // With our fix: crashed flag cleared AFTER successful manual restart
            process.crash.crashed = false;
            process.last_action_at = Utc::now();
        }

        assert_eq!(
            runner.info(id).unwrap().running,
            true,
            "Manual restart should succeed and process should be running"
        );
        assert_eq!(
            runner.info(id).unwrap().crash.crashed,
            false,
            "After successful manual restart, crashed flag should be cleared"
        );
        assert_eq!(
            runner.info(id).unwrap().restarts,
            10,
            "Manual restart does not reset crash counter (preserves history at 10)"
        );

        // Process crashes again after manual restart
        {
            let process = runner.process(id);
            process.pid = 0; // Process died again
        }

        // Daemon detects the new crash - THIS IS THE CRITICAL TEST
        // Before the fix, crashed=false was set too early and this wouldn't work
        // After the fix, crashed=false is only set after successful restart, so detection works
        {
            let process_info = runner.info(id).unwrap();
            if !process_info.crash.crashed {
                let process = runner.process(id);
                process.restarts += 1;
                process.crash.crashed = true;
            }
        }

        // CRITICAL VERIFICATION: Counter should increment from 10 to 11
        assert_eq!(
            runner.info(id).unwrap().restarts,
            11,
            "After manual restart and crash, counter MUST increment from 10 to 11 (verifying fix works!)"
        );
        assert_eq!(
            runner.info(id).unwrap().crash.crashed,
            true,
            "Process should be marked as crashed after new crash"
        );
    }

    #[test]
    fn test_compact_process_ids() {
        // Test that process IDs are compacted (reindexed) after removal
        let mut runner = setup_test_runner();

        // Create 5 processes - ID counter starts at 1, so IDs will be 1, 2, 3, 4, 5
        // After compaction, IDs will be renumbered starting from 0
        for i in 0..5 {
            let id = runner.id.next();
            let process = Process {
                id,
                pid: 1000 + i as i64,
                shell_pid: None,
                env: BTreeMap::new(),
                name: format!("process_{}", i),
                path: PathBuf::from("/tmp"),
                script: "echo 'test'".to_string(),
                restarts: 0,
                running: true,
                crash: Crash { crashed: false },
                watch: Watch {
                    enabled: false,
                    path: String::new(),
                    hash: String::new(),
                },
                children: vec![],
                started: Utc::now(),
                max_memory: 0,
                agent_id: None,
                frozen_until: None,
                last_action_at: Utc::now(),
                manual_stop: false,
                errored: false,
                last_restart_attempt: None,
                failed_restart_attempts: 0,
                session_id: None,
            process_start_time: None,
            is_process_tree: false,
            };
            runner.list.insert(id, process);
        }

        // Verify initial state - should have IDs 1, 2, 3, 4, 5
        assert_eq!(runner.list.len(), 5, "Should have 5 processes");
        assert!(runner.exists(1), "Process 1 should exist");
        assert!(runner.exists(2), "Process 2 should exist");
        assert!(runner.exists(3), "Process 3 should exist");
        assert!(runner.exists(4), "Process 4 should exist");
        assert!(runner.exists(5), "Process 5 should exist");

        // Remove processes 1 and 3 (creating gaps)
        runner.list.remove(&1);
        runner.list.remove(&3);

        // Before compact: IDs should be 2, 4, 5 (with gaps)
        assert_eq!(
            runner.list.len(),
            3,
            "Should have 3 processes after removal"
        );
        assert!(!runner.exists(1), "Process 1 should not exist");
        assert!(runner.exists(2), "Process 2 should still exist");
        assert!(!runner.exists(3), "Process 3 should not exist");
        assert!(runner.exists(4), "Process 4 should still exist");
        assert!(runner.exists(5), "Process 5 should still exist");

        // Now compact the IDs
        runner.compact();

        // After compact: IDs should be 0, 1, 2 (sequential starting from 0)
        assert_eq!(runner.list.len(), 3, "Should still have 3 processes");
        assert!(runner.exists(0), "Process 0 should exist after compact");
        assert!(runner.exists(1), "Process 1 should exist after compact");
        assert!(runner.exists(2), "Process 2 should exist after compact");
        assert!(
            !runner.exists(3),
            "Process 3 should not exist after compact"
        );
        assert!(
            !runner.exists(4),
            "Process 4 should not exist after compact"
        );
        assert!(
            !runner.exists(5),
            "Process 5 should not exist after compact"
        );

        // Verify the names are correct (should maintain order)
        assert_eq!(
            runner.info(0).unwrap().name,
            "process_1",
            "First process should be process_1 (was ID 2)"
        );
        assert_eq!(
            runner.info(1).unwrap().name,
            "process_3",
            "Second process should be process_3 (was ID 4)"
        );
        assert_eq!(
            runner.info(2).unwrap().name,
            "process_4",
            "Third process should be process_4 (was ID 5)"
        );

        // Verify ID counter is reset correctly
        let next_id = runner.id.next();
        assert_eq!(next_id, 3, "Next ID should be 3 (after processes 0, 1, 2)");
    }

    #[test]
    fn test_counter_consistency_across_crash_restart_cycles() {
        // Test that the restart counter is displayed consistently regardless of crash state
        // This validates the fix for the issue where counter would jump between values
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Start with a process that has crashed 10 times
        let process = Process {
            id,
            pid: 0,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 10,
            running: false,
            crash: Crash { crashed: true },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process.clone());

        // Verify initial state - should show crash.value (10)
        let process_item = runner.build_process_item(id, &process);
        assert_eq!(
            process_item.restarts, 10,
            "Should display crash.value (10) when crashed"
        );

        // Simulate manual restart (increment_counter=true)
        let proc = runner.process(id);
        proc.restarts += 1; // Only increment once now that we have a single counter
        proc.crash.crashed = false; // Successful restart clears crashed flag
        proc.running = true;
        proc.pid = 12345;

        // After successful restart with increment_counter=true, counter should be 11
        assert_eq!(
            runner.info(id).unwrap().restarts,
            11,
            "restarts counter should be 11 after increment"
        );

        // Verify ProcessItem always shows restarts counter (now 11) even when not crashed
        let updated_process = runner.info(id).unwrap().clone();
        let process_item = runner.build_process_item(id, &updated_process);
        assert_eq!(
            process_item.restarts, 11,
            "Should display crash.value (11) consistently even when not crashed"
        );

        // Simulate another crash (daemon detects and increments crash.value)
        let proc = runner.process(id);
        proc.restarts += 1;
        proc.crash.crashed = true;
        proc.running = false;
        proc.pid = 0;

        // Both counters should be in sync
        assert_eq!(
            runner.info(id).unwrap().restarts,
            12,
            "crash.value should be 12 after crash"
        );

        // Verify display continues to show crash.value (12)
        let crashed_process = runner.info(id).unwrap().clone();
        let process_item = runner.build_process_item(id, &crashed_process);
        assert_eq!(
            process_item.restarts, 12,
            "Should display crash.value (12) consistently when crashed again"
        );
    }

    #[test]
    fn test_remove_multiple_ids_with_descending_order() {
        // Test that removing multiple IDs in descending order prevents ID shift issues
        // This validates the fix for the issue where deleting IDs 3,4 would fail on the second deletion
        // because ID 4 would become ID 3 after the first deletion's compaction
        let mut runner = setup_test_runner();

        // Create 6 processes - IDs will be 1, 2, 3, 4, 5, 6
        for i in 0..6 {
            let id = runner.id.next();
            let process = Process {
                id,
                pid: (2000 + i) as i64,
                shell_pid: None,
                env: BTreeMap::new(),
                name: format!("process_{}", i),
                path: PathBuf::from("/tmp"),
                script: "echo 'test'".to_string(),
                restarts: 0,
                running: true,
                crash: Crash { crashed: false },
                watch: Watch {
                    enabled: false,
                    path: String::new(),
                    hash: String::new(),
                },
                children: vec![],
                started: Utc::now(),
                max_memory: 0,
                agent_id: None,
                frozen_until: None,
                last_action_at: Utc::now(),
                manual_stop: false,
                errored: false,
                last_restart_attempt: None,
                failed_restart_attempts: 0,
                session_id: None,
            process_start_time: None,
            is_process_tree: false,
            };
            runner.list.insert(id, process);
        }

        // Verify initial state - should have IDs 1-6
        assert_eq!(runner.list.len(), 6, "Should have 6 processes");
        for i in 1..=6 {
            assert!(runner.exists(i), "Process {} should exist", i);
        }

        // Simulate deleting IDs 3 and 4 - must be done in descending order (4, then 3)
        // to prevent ID shift issues from compaction
        // Step-by-step:
        // Before: 1(p0), 2(p1), 3(p2), 4(p3), 5(p4), 6(p5)
        // Remove 4: 1(p0), 2(p1), 3(p2), 5(p4), 6(p5)
        // Compact: 0(p0), 1(p1), 2(p2), 3(p4), 4(p5)
        // Remove 3: 0(p0), 1(p1), 2(p2), 4(p5)
        // Compact: 0(p0), 1(p1), 2(p2), 3(p5)
        let mut ids_to_remove = vec![3, 4];
        ids_to_remove.sort_by(|a, b| b.cmp(a)); // Sort descending

        for id in ids_to_remove {
            // Remove and compact (simulating what happens in actual removal)
            runner.list.remove(&id);
            runner.compact();
        }

        // After removal and compaction
        assert_eq!(
            runner.list.len(),
            4,
            "Should have 4 processes after removal"
        );

        // Verify compaction happened correctly - IDs should be sequential 0-3
        assert!(runner.exists(0), "Process 0 should exist");
        assert!(runner.exists(1), "Process 1 should exist");
        assert!(runner.exists(2), "Process 2 should exist");
        assert!(runner.exists(3), "Process 3 should exist");

        // Verify the names - should be process_0, process_1, process_2, process_5
        // (process_3 and process_4 were removed via IDs 4 and 3)
        assert_eq!(
            runner.info(0).unwrap().name,
            "process_0",
            "ID 0 should be process_0"
        );
        assert_eq!(
            runner.info(1).unwrap().name,
            "process_1",
            "ID 1 should be process_1"
        );
        assert_eq!(
            runner.info(2).unwrap().name,
            "process_2",
            "ID 2 should be process_2"
        );
        assert_eq!(
            runner.info(3).unwrap().name,
            "process_5",
            "ID 3 should be process_5"
        );

        // Verify ID counter is correct
        let next_id = runner.id.next();
        assert_eq!(next_id, 4, "Next ID should be 4");
    }

    #[test]
    fn test_remove_marks_process_as_stopped() {
        // Test that remove_direct_internal marks process as stopped before removing
        // This validates the fix to prevent auto-restart during removal
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 3000,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 0,
            running: true, // Process is running
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify process is running initially
        assert!(
            runner.info(id).unwrap().running,
            "Process should be running initially"
        );

        // Note: We can't directly test remove_direct_internal as it would try to kill the process
        // Instead, we test the logic by manually simulating the steps

        // Step 1: Mark as stopped (what remove_direct_internal should do first)
        if runner.exists(id) {
            runner.process(id).running = false;
        }

        // Verify process is marked as stopped
        assert!(
            !runner.info(id).unwrap().running,
            "Process should be marked as stopped"
        );

        // Step 2: Remove from list (this would happen after marking as stopped)
        runner.list.remove(&id);

        // Verify process is removed
        assert!(!runner.exists(id), "Process should be removed from list");
    }

    #[test]
    fn test_crashed_process_status_consistency() {
        // Test that crashed processes maintain consistent status
        // This validates the fix where processes shouldn't change from "crashed" to "stopped"
        // unless explicitly stopped by the user
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process that has crashed
        let process = Process {
            id,
            pid: 0, // PID of 0 indicates process is not running
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_crashed_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "exit 1".to_string(),
            restarts: 1,    // Had crashed once
            running: false, // Not running
            crash: Crash {
                crashed: true, // Marked as crashed
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now() - chrono::Duration::seconds(10),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify the process is marked as crashed
        let info = runner.info(id).unwrap();
        assert!(info.crash.crashed, "Process should be marked as crashed");
        assert_eq!(info.restarts, 1, "Restart count should be 1");
        assert!(!info.running, "Process should not be running");
        assert_eq!(info.pid, 0, "PID should be 0");

        // This test validates that the fix prevents the incorrect state transition:
        // crashed (crash.crashed=true) -> stopped (crash.crashed=false)
        // that was happening when no process handle was found.
        //
        // The fix ensures that only processes with handles AND successful exit codes
        // are treated as clean stops. Processes without handles (like this one)
        // should maintain their crashed state and go through proper crash handling.

        let info_after = runner.info(id).unwrap();
        assert!(info_after.crash.crashed,
                "Crashed flag should remain true - process shouldn't transition to stopped without explicit user action or successful exit");
    }

    #[test]
    fn test_crashed_process_remains_in_list() {
        // Test that a crashed process remains in the list and is not automatically removed
        // This validates the fix for issue: "fix li tin trnh bin mt ngay sau khi start"
        // (fix bug where process disappears immediately after start)
        //
        // Scenario: User starts a process that crashes immediately
        // Expected: Process should remain in the list with crashed status
        // Bug: Process was disappearing from the list on subsequent `opm ls` calls
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process that has crashed immediately after start
        let process = Process {
            id,
            pid: 0, // No valid PID (process died)
            shell_pid: None,
            env: BTreeMap::new(),
            name: "tets".to_string(), // Using same name as in the issue report
            path: PathBuf::from("/tmp"),
            script: "tets".to_string(), // Non-existent command
            restarts: 10,               // Had restarted 10 times and hit limit
            running: false,             // Daemon marked as not running after max restarts
            crash: Crash {
                crashed: true, // Marked as crashed
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify the process is in the list
        assert!(
            runner.exists(id),
            "Crashed process should exist in the list"
        );
        assert_eq!(
            runner.list.len(),
            1,
            "List should contain exactly one process"
        );

        // Simulate multiple list operations (as user would run `opm ls` multiple times)
        let items1 = runner.items();
        assert!(
            items1.contains_key(&id),
            "Process should be in items() after first call"
        );

        let items2 = runner.items();
        assert!(
            items2.contains_key(&id),
            "Process should still be in items() after second call"
        );

        // Verify process details
        let info = runner.info(id).unwrap();
        assert!(info.crash.crashed, "Process should be marked as crashed");
        assert!(!info.running, "Process should not be running");
        assert_eq!(info.restarts, 10, "Crash count should be 10");

        // Verify the process remains in the list even after checking multiple times
        assert!(
            runner.exists(id),
            "Crashed process should still exist after multiple queries"
        );
        assert_eq!(runner.list.len(), 1, "List size should remain unchanged");
    }

    #[test]
    fn test_successful_exit_clears_crashed_flag() {
        // Test that when a process that previously crashed exits successfully,
        // the crashed flag is cleared so it shows as "stopped" instead of "crashed"
        // This validates the fix where successful exits should clear crash.crashed
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process that had previously crashed but is now stopped cleanly
        let process = Process {
            id,
            pid: 0,
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_clean_exit".to_string(),
            path: PathBuf::from("/tmp"),
            script: "exit 0".to_string(),
            restarts: 5,    // Had restarted 5 times
            running: false, // Stopped cleanly
            crash: Crash {
                crashed: true, // Was previously marked as crashed
            },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now() - chrono::Duration::seconds(10),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process.clone());

        // Verify initial state - crashed flag is true
        let info = runner.info(id).unwrap();
        assert!(
            info.crash.crashed,
            "Process should initially be marked as crashed"
        );
        assert_eq!(info.restarts, 5, "Restart count should be 5");

        // Get the status - should show as "crashed" because crashed=true
        let processes = runner.fetch();
        assert_eq!(
            processes[0].status, "crashed",
            "Process with crashed=true should show as crashed"
        );

        // Simulate successful exit by clearing the crashed flag
        // (This is what the daemon should do when it detects a successful exit)
        if runner.exists(id) {
            let process = runner.process(id);
            process.crash.crashed = false;
            process.last_action_at = Utc::now();
        }

        // Verify the crashed flag was cleared
        let info_after = runner.info(id).unwrap();
        assert!(
            !info_after.crash.crashed,
            "Crashed flag should be cleared after successful exit"
        );
        assert_eq!(
            info_after.restarts, 5,
            "Crash count should remain unchanged (preserves history)"
        );

        // Get the status again - should now show as "stopped" because crashed=false
        let processes_after = runner.fetch();
        assert_eq!(
            processes_after[0].status, "stopped",
            "Process with crashed=false should show as stopped after successful exit"
        );
    }

    #[test]
    fn test_stop_clears_shell_pid() {
        // Test that shell_pid must be cleared when stopping a process
        // This prevents the daemon monitoring loop from treating the stopped process as crashed
        // Bug: If shell_pid is not cleared, monitor sees shell_pid.unwrap_or(pid) > 0 and
        //      incorrectly marks the stopped process as crashed
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process with a shell_pid set (simulating a process that was started via shell)
        let process = Process {
            id,
            pid: 12345,
            shell_pid: Some(12346), // Shell PID is set
            env: BTreeMap::new(),
            name: "test_shell_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify initial state - both pid and shell_pid are set
        let info_before = runner.info(id).unwrap();
        assert_eq!(info_before.pid, 12345, "PID should be set initially");
        assert_eq!(
            info_before.shell_pid,
            Some(12346),
            "Shell PID should be set initially"
        );
        assert!(info_before.running, "Process should be running initially");

        // Manually simulate what stop() should do (without calling save() which requires global placeholders)
        // This is the critical part: both pid and shell_pid must be cleared
        let process = runner.process(id);
        process.running = false;
        process.crash.crashed = false;
        process.last_action_at = Utc::now();
        process.children = vec![];
        process.pid = 0;
        process.shell_pid = None; // This is the fix being tested - shell_pid must be None

        // Verify that both pid and shell_pid are cleared
        let info_after = runner.info(id).unwrap();
        assert_eq!(
            info_after.pid, 0,
            "PID should be cleared (set to 0) after stop"
        );
        assert_eq!(
            info_after.shell_pid, None,
            "Shell PID should be cleared (set to None) after stop - THIS IS THE FIX"
        );
        assert!(
            !info_after.running,
            "Process should not be running after stop"
        );
        assert!(
            !info_after.crash.crashed,
            "Process should not be marked as crashed after stop"
        );

        // Verify status shows as "stopped" not "crashed"
        let processes = runner.fetch();
        assert_eq!(
            processes[0].status, "stopped",
            "Stopped process should show as 'stopped' not 'crashed'"
        );
    }

    #[test]
    fn test_shell_wrapped_process_not_crashed_when_shell_alive() {
        // Test that shell-wrapped processes show as online when shell_pid is alive
        // even if the actual child PID check fails
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Get the current process PID (this test process itself) - we know it's alive
        let alive_pid = std::process::id() as i64;

        let process = Process {
            id,
            pid: UNLIKELY_PID,          // Dead PID (actual child)
            shell_pid: Some(alive_pid), // Alive shell PID (our test process)
            env: BTreeMap::new(),
            name: "test_shell_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "node server.js".to_string(),
            restarts: 0,
            running: true, // Marked as running
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Fetch the process list and check status
        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");

        // The shell_pid is alive (our test process), so status should be "online"
        // even though the actual child pid (UNLIKELY_PID) is dead
        assert_eq!(
            processes[0].status, "online",
            "Process with alive shell_pid should show as online even if child pid is dead"
        );
    }

    #[test]
    fn test_is_pid_alive_with_eperm() {
        // Test that is_pid_alive correctly handles EPERM (permission denied)
        // When kill(pid, 0) returns EPERM, it means the process exists but we don't have permission
        // This should be treated as "process is alive"

        // Test with PID 1 (init/systemd) which always exists
        // We may not have permission to signal it, but it should still be considered alive
        let init_alive = is_pid_alive(1);
        assert!(init_alive, "PID 1 (init) should always be considered alive");

        // Test with our own process (we definitely have permission)
        let own_pid = std::process::id() as i64;
        let own_alive = is_pid_alive(own_pid);
        assert!(own_alive, "Our own process should be considered alive");

        // Test with non-existent PID (should return false)
        let unlikely_pid_alive = is_pid_alive(UNLIKELY_PID);
        assert!(
            !unlikely_pid_alive,
            "Non-existent process should be considered dead"
        );

        // Test with invalid PIDs (should return false)
        assert!(!is_pid_alive(0), "PID 0 should be considered invalid");
        assert!(
            !is_pid_alive(-1),
            "Negative PID should be considered invalid"
        );
    }

    #[test]
    fn test_started_process_shows_correct_status() {
        // Test that a process started with a valid PID shows as "online" not "stopped"
        // This validates the fix for the issue where processes would incorrectly show as "stopped"
        // immediately after being started, even though they were actually running,
        // because the state wasn't persisted properly between CLI commands.

        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Create a process that was just started (simulating what happens after opm start)
        // Use the current process PID to simulate a running process
        let current_pid = std::process::id() as i64;

        let process = Process {
            id,
            pid: current_pid, // Use a valid, alive PID
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_started_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'hello'".to_string(),
            restarts: 0,
            running: true, // Process was just started, so running=true
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Fetch the process list to check status (this is what happens with opm ls)
        let processes = runner.fetch();
        assert_eq!(processes.len(), 1, "Should have one process");

        // The process should show as "online" not "stopped" because:
        // 1. running=true (was just started)
        // 2. pid is alive (we're using current process PID)
        // 3. crashed=false (no crash yet)
        assert_eq!(
            processes[0].status, "online",
            "Started process with valid PID should show as online, not stopped"
        );

        // Verify it's the correct process
        assert_eq!(processes[0].name, "test_started_process");
        assert_eq!(processes[0].pid, current_pid);
    }

    #[test]
    fn test_child_adoption_when_parent_exits() {
        // This test validates the fix for the issue where shell scripts that spawn
        // background processes would be incorrectly marked as crashed when the shell exits.
        // The daemon should adopt the child process as the new monitored PID.

        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Simulate a process where the parent shell has exited (pid is dead)
        // but a child process is still running
        let dead_pid = UNLIKELY_PID; // Parent shell PID (dead)
        let alive_child_pid = std::process::id() as i64; // Child process PID (alive - using current process)

        let process = Process {
            id,
            pid: dead_pid, // Parent shell is dead
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_parent_exits".to_string(),
            path: PathBuf::from("/tmp"),
            script: "start.sh".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![alive_child_pid], // Child is still alive
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Before the fix, the daemon would mark this as crashed and set pid=0
        // After the fix, it should adopt the child process

        // Note: We can't directly test the daemon monitoring loop here,
        // but we can verify that is_pid_alive correctly identifies the states:
        assert!(!is_pid_alive(dead_pid), "Parent PID should be dead");
        assert!(is_pid_alive(alive_child_pid), "Child PID should be alive");

        // Verify the children list contains the alive child
        let proc = runner.process(id);
        assert_eq!(proc.children.len(), 1, "Should have one child");
        assert_eq!(
            proc.children[0], alive_child_pid,
            "Child should be the alive PID"
        );

        // After daemon adoption (which happens in daemon/mod.rs), the process should:
        // 1. Have its pid updated to the alive child
        // 2. Have the child removed from the children list
        // 3. Continue to be marked as running (not crashed)
        // This is what the daemon fix implements
    }

    #[test]
    fn test_background_descendant_not_crashed() {
        // Test that a background shell script with a living descendant is NOT marked as crashed
        // The descendant being alive should prevent crash marking
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Use current process PID as a simulated "alive descendant"
        let alive_descendant = std::process::id() as i64;
        let dead_root_pid = UNLIKELY_PID;

        let process = Process {
            id,
            pid: dead_root_pid, // Root PID is dead
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_background_shell".to_string(),
            path: PathBuf::from("/tmp"),
            script: "a.sh".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![alive_descendant], // But descendant is alive
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Verify that is_any_descendant_alive detects the living descendant
        let item = runner.info(id).unwrap();
        assert!(
            is_any_descendant_alive(item.pid, &item.children),
            "Should detect living descendant even when root PID is dead"
        );
        assert!(
            !is_pid_info_missing(item.pid, &item.children),
            "PID info should NOT be missing - we have a tracked descendant"
        );
    }

    #[test]
    fn test_per_process_delay_skips_crash() {
        // Test that crash detection is skipped within 5s of last_action_at
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: UNLIKELY_PID, // Dead PID
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_delay_process".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo test".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![], // No descendants
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        let item = runner.info(id).unwrap();
        let seconds_since_action = (Utc::now() - item.last_action_at).num_seconds();

        // Should be within 5s delay
        assert!(
            seconds_since_action < 5,
            "Should be within 5s delay immediately after creation"
        );

        // Simulate daemon check - process should NOT be marked crashed within delay
        // (The actual daemon would skip crash marking when within_action_delay is true)
        assert!(
            !item.crash.crashed,
            "Process should NOT be marked crashed within 5s delay"
        );
    }

    #[test]
    fn test_missing_pid_info_skips_crash() {
        // Test that missing/incomplete PID info logs error and does NOT mark crashed
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        let process = Process {
            id,
            pid: 0, // Invalid PID (<= 0)
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_missing_pid".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo test".to_string(),
            restarts: 0,
            running: true,
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![], // No tracked descendants
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now(),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        let item = runner.info(id).unwrap();

        // Verify PID info is detected as missing
        assert!(
            is_pid_info_missing(item.pid, &item.children),
            "PID info should be missing when pid <= 0 and no children"
        );

        // The daemon should:
        // 1. Log an error about missing PID info
        // 2. NOT mark the process as crashed (no crash counter increment)
        // 3. Continue to the next process

        // Verify crash counter was NOT incremented
        assert_eq!(
            item.restarts, 0,
            "Crash counter should NOT be incremented when PID info is missing"
        );
        assert!(
            !item.crash.crashed,
            "Process should NOT be marked crashed when PID info is missing"
        );
    }

    #[test]
    fn test_restore_pid_preserved_across_daemon_save() {
        // Test that when restore updates a process PID mid-cycle,
        // the daemon doesn't overwrite it with stale pid=0 when it saves.
        //
        // This tests the fix for the phantom crash/stop issue where:
        // 1. LoadPermanent loads dump with pid=0
        // 2. Daemon monitoring loop starts with runner having pid=0
        // 3. Restore updates PID to 12345 via SetState
        // 4. Daemon saves its stale runner (pid=0), which should NOT overwrite the fresh PID
        //
        // The fix: SetState handler preserves existing PID when incoming has pid=0
        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Unix epoch constant used throughout the test
        let unix_epoch = chrono::DateTime::from_timestamp(0, 0)
            .expect("Unix epoch timestamp should always be valid");

        // Simulate process after LoadPermanent - has all fields but pid=0 (default after deserialization)
        let process_from_dump = Process {
            id,
            pid: 0, // Default after deserialization (not persisted)
            shell_pid: None,
            env: BTreeMap::new(),
            name: "uptimekuma".to_string(),
            path: PathBuf::from("/home/container/uptime-kuma"),
            script: "node server/server.js".to_string(),
            restarts: 0,
            running: true, // Was running before daemon restart
            crash: Crash { crashed: false },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: unix_epoch, // Unix epoch (default)
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: unix_epoch,
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process_from_dump.clone());

        // Verify initial state - process has pid=0
        let info_before = runner.info(id).unwrap();
        assert_eq!(
            info_before.pid, 0,
            "Process should have pid=0 after LoadPermanent"
        );
        assert!(info_before.running, "Process should be marked as running");

        // Simulate restore starting the process and updating PID via SetState
        // This is what happens when restore calls runner.restart() and then save()
        let mut process_after_restore = process_from_dump.clone();
        process_after_restore.pid = 12345; // Fresh PID assigned by restore
        process_after_restore.children = vec![12346, 12347]; // Discovered children
        process_after_restore.started = Utc::now(); // Fresh start time

        // Update the process - this simulates SetState being called
        runner.list.insert(id, process_after_restore);

        // Verify PID was updated
        let info_after_restore = runner.info(id).unwrap();
        assert_eq!(
            info_after_restore.pid, 12345,
            "Process should have fresh PID after restore"
        );
        assert_eq!(
            info_after_restore.children.len(),
            2,
            "Process should have 2 children"
        );

        // Now simulate daemon's monitoring loop saving its stale runner (pid=0)
        // This is the problematic case - daemon loaded state before restore updated it
        // and now tries to save its stale copy
        let mut daemon_stale_runner = process_from_dump.clone();
        daemon_stale_runner.pid = 0; // Stale PID from daemon's old runner
        daemon_stale_runner.shell_pid = None;
        daemon_stale_runner.children = vec![]; // Stale children list
        daemon_stale_runner.started = unix_epoch; // Stale start time

        // The fix: When merging in SetState handler, if existing has pid>0 but incoming has pid=0,
        // preserve the existing PID. We simulate this merge logic here.
        let existing = runner.info(id).unwrap();
        let mut merged = daemon_stale_runner;

        // Apply the merge logic from the fix
        if existing.pid > 0 && merged.pid == 0 {
            merged.pid = existing.pid;
            merged.shell_pid = existing.shell_pid;
            merged.children = existing.children.clone();
            if existing.started != unix_epoch {
                merged.started = existing.started;
            }
        }

        runner.list.insert(id, merged);

        // Verify the fresh PID is preserved, not overwritten with stale pid=0
        let info_final = runner.info(id).unwrap();
        assert_eq!(
            info_final.pid, 12345,
            "Fresh PID should be preserved, not overwritten with stale pid=0"
        );
        assert_eq!(
            info_final.children.len(),
            2,
            "Children list should be preserved"
        );
        assert_ne!(
            info_final.started, unix_epoch,
            "Start time should be preserved, not reset to Unix epoch"
        );

        // Verify status shows as "online" or "starting" (grace period), not "stopped"
        let processes = runner.fetch();
        assert!(
            processes[0].status == "online" || processes[0].status == "starting",
            "Process with valid PID should show as online or starting, got: {}",
            processes[0].status
        );
    }

    #[test]
    fn test_restart_counter_not_incremented_on_retry() {
        // Test for the fix: restart counter should only be incremented once per actual
        // restart attempt, not on every daemon cycle when restart fails.
        //
        // Bug scenario:
        // 1. Process crashes and daemon tries to restart
        // 2. Restart fails (e.g., bad working directory), pid=0, running=true
        // 3. On next daemon cycle, counter was being incremented AGAIN (bug!)
        // 4. This repeated every cycle until limit reached
        //
        // Fix: Only increment counter if pid > 0 (process was actually running)
        // If pid = 0, it's a retry of the same failed restart, not a new crash

        let mut runner = setup_test_runner();
        let id = runner.id.next();

        // Scenario 1: Process with pid=0 (restart failed/pending)
        // Counter should NOT be incremented
        let process = Process {
            id,
            pid: 0, // No PID - restart failed or never started
            shell_pid: None,
            env: BTreeMap::new(),
            name: "test_retry_counter".to_string(),
            path: PathBuf::from("/tmp"),
            script: "echo 'test'".to_string(),
            restarts: 1,   // Counter was already incremented once
            running: true, // Auto-restart enabled
            crash: Crash { crashed: true },
            watch: Watch {
                enabled: false,
                path: String::new(),
                hash: String::new(),
            },
            children: vec![],
            started: Utc::now(),
            max_memory: 0,
            agent_id: None,
            frozen_until: None,
            last_action_at: Utc::now() - chrono::Duration::seconds(10),
            manual_stop: false,
            errored: false,
            last_restart_attempt: None,
            failed_restart_attempts: 0,
            session_id: None,
            process_start_time: None,
            is_process_tree: false,
        };

        runner.list.insert(id, process);

        // Simulate daemon checking if counter should increment (the fix)
        let proc = runner.info(id).unwrap().clone();
        let is_new_crash = proc.pid > 0; // Fix: only increment if pid > 0

        assert_eq!(
            is_new_crash, false,
            "Should NOT increment when pid=0 (retry of failed restart)"
        );

        // Verify counter remains unchanged
        assert_eq!(runner.info(id).unwrap().restarts, 1);

        // Scenario 2: Process with pid > 0 (actually running)
        // Counter SHOULD be incremented when it crashes
        {
            let process = runner.process(id);
            process.pid = 12345; // Process is running
        }

        let proc = runner.info(id).unwrap().clone();
        let is_new_crash = proc.pid > 0;

        assert_eq!(
            is_new_crash, true,
            "Should increment when pid > 0 (process was running)"
        );
    }

    #[test]
    fn test_command_needs_shell_detection() {
        // Test shell operator detection
        assert!(
            command_needs_shell("echo hello | grep world"),
            "Pipe should need shell"
        );
        assert!(
            command_needs_shell("echo hello && echo world"),
            "AND operator should need shell"
        );
        assert!(
            command_needs_shell("echo hello || echo world"),
            "OR operator should need shell"
        );
        assert!(
            command_needs_shell("echo hello > output.txt"),
            "Redirect should need shell"
        );
        assert!(
            command_needs_shell("echo hello >> output.txt"),
            "Append redirect should need shell"
        );
        assert!(
            command_needs_shell("cat < input.txt"),
            "Input redirect should need shell"
        );
        assert!(
            command_needs_shell("echo hello; echo world"),
            "Semicolon should need shell"
        );
        // Note: Single & removed from detection to avoid false positives with URLs/hex values
        assert!(
            command_needs_shell("echo `date`"),
            "Command substitution (backticks) should need shell"
        );
        assert!(
            command_needs_shell("echo $(date)"),
            "Command substitution ($()) should need shell"
        );
        assert!(
            command_needs_shell("cd ~/projects"),
            "Tilde expansion should need shell"
        );
        assert!(
            command_needs_shell("ls *.txt"),
            "Glob pattern should need shell"
        );
        assert!(
            command_needs_shell("export PATH=/usr/bin"),
            "Export should need shell"
        );

        // Test simple commands that don't need shell
        assert!(
            !command_needs_shell("node server.js"),
            "Simple node command should not need shell"
        );
        assert!(
            !command_needs_shell("python app.py"),
            "Simple python command should not need shell"
        );
        assert!(
            !command_needs_shell("./binary --flag value"),
            "Binary with flags should not need shell"
        );
        assert!(
            !command_needs_shell("echo hello"),
            "Simple echo should not need shell"
        );
    }

    #[test]
    fn test_parse_direct_command() {
        // Test successful parsing
        let result = parse_direct_command("node server.js");
        assert!(result.is_some());
        let (program, args) = result.unwrap();
        assert_eq!(program, "node");
        assert_eq!(args, vec!["server.js"]);

        let result = parse_direct_command("python app.py --port 8080");
        assert!(result.is_some());
        let (program, args) = result.unwrap();
        assert_eq!(program, "python");
        assert_eq!(args, vec!["app.py", "--port", "8080"]);

        // Test empty command
        let result = parse_direct_command("");
        assert!(result.is_none());

        // Test whitespace only
        let result = parse_direct_command("   ");
        assert!(result.is_none());

        // Test single program with no args
        let result = parse_direct_command("node");
        assert!(result.is_some());
        let (program, args) = result.unwrap();
        assert_eq!(program, "node");
        assert_eq!(args.len(), 0);
    }

    #[test]
    fn test_kill_old_processes_before_restore_no_session_ids() {
        // Test that kill_old_processes_before_restore safely skips killing when no session IDs are available
        // This is critical to prevent killing unrelated processes
        let processes = vec![
            (1, "node server.js".to_string(), None),
            (2, "python app.py".to_string(), None),
            (3, "java -jar app.jar".to_string(), None),
        ];

        // Should return Ok and not panic or kill anything
        let result = kill_old_processes_before_restore(&processes);
        assert!(result.is_ok(), "Should succeed without session IDs");
    }

    #[test]
    fn test_kill_old_processes_before_restore_empty_list() {
        // Test that an empty process list is handled correctly
        let processes = vec![];
        let result = kill_old_processes_before_restore(&processes);
        assert!(result.is_ok(), "Should succeed with empty list");
    }
}
